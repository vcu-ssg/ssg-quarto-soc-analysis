{
  "hash": "f90568dceeca46526555b0e2f96f6950",
  "result": {
    "markdown": "---\ntitle: Cleaning the data\n---\n\nThis script describes the data and walks through a process of data cleaning.\n\nAt completion of this script all the individual semester data files will be combined into a single dataframe for analysis, and the dataframe will be refactored for cleaner analysis.\n\n## Data sources\n\nThe files are named appropriately and stored in the *data* folder in this repository.\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\nFile name                   Term Code    Acad Year    Period Code    Period Name\n--------------------------  -----------  -----------  -------------  -------------\nVCU-SOC-202110-FA2020.xlsx  202110       AY20-21      FA2020         Fall 2020\nVCU-SOC-202120-SP2021.xlsx  202120       AY20-21      SP2021         Spring 2021\nVCU-SOC-202130-SU2021.xlsx  202130       AY20-21      SU2021         Summer 2021\nVCU-SOC-202210-FA2021.xlsx  202210       AY21-22      FA2021         Fall 2021\nVCU-SOC-202220-SP2022.xlsx  202220       AY21-22      SP2022         Spring 2022\nVCU-SOC-202230-SU2022.xlsx  202230       AY21-22      SU2022         Summer 2022\nVCU-SOC-202310-FA2022.xlsx  202310       AY22-23      FA2022         Fall 2022\nVCU-SOC-202320-SP2023.xlsx  202320       AY22-23      SP2023         Spring 2023\nVCU-SOC-202330-SU2023.xlsx  202330       AY22-23      SU2023         Summer 2023\nVCU-SOC-202410-FA2023.xlsx  202410       AY23-24      FA2023         Fall 2023\n:::\n:::\n\n\n## Data Cleaning\n\nThe following sections combine the individual sources of data and clean them up.\n\n### Combining to single data frame\n\nThe following section combines each XLSX into a single data frame.  The contents of the files are variable in length depending on the number of sections taught\nduring any given semester.\n\nThe appropriate block starts one row after the row with the keyword *TERM* in the first column, denoting the header row.  The appropriate block ends with the row prior to the row with the keyword *N =*. \n\nWe're assuming that all xlsx workbooks share the same columns and names.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Initialize an empty list to store trimmed DataFrames\ntrimmed_dfs = []\n\n# Iterate through the list of XLSX file names\nfor file_name in xlsx_df['file_name']:\n    # Load the XLSX file into a DataFrame\n    full_path = os.path.join(directory_path, file_name)\n    df = pd.read_excel(full_path)\n    \n    # Find the row index where \"TERM\" is in the first column\n    term_index = df.index[df.iloc[:, 0] == \"TERM\"].tolist()[0]\n    \n    # Find the row index where \"N=\" is in the first column\n    n_index = df.index[df.iloc[:, 0].str.startswith(\"N =\").fillna(False)].tolist()[0]\n\n    # Clip the desired block and add column names\n    trimmed_df = df.loc[term_index + 1 : n_index - 1]\n    trimmed_df.columns = df.iloc[term_index].values\n\n    # Append the trimmed DataFrame to the list\n    trimmed_dfs.append(trimmed_df)\n\n# Combine the individual dataframes into one big one.\nsections_df = pd.concat(trimmed_dfs, ignore_index=True)\n```\n:::\n\n\n### Merge in the term and period data from the xlsx_df dataframe\n\nThe following code merges in the term and period data with the section data.\nFirst ensure that the key columns are strings, then merge away.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nsections_df['SECT'] = sections_df['SECT'].astype(str)\nsections_df['TERM'] = sections_df['TERM'].astype(str)\nxlsx_df['term_code'] = xlsx_df['term_code'].astype(str)\nsections_df = pd.merge(sections_df,xlsx_df,left_on='TERM', right_on='term_code', how='left')\n```\n:::\n\n\n### Fix known errors\n\nThe data in Banner doesn't always reflect reality.  This step corrects\nknown errors in the data.\n\nNote that the section data are stored one row per term-crn-meeting period.\n\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# Spring 2023: CMSC475 John Leonard taught for David Shepherd\nfix(1,'Swap Leonard for Shepherd',{'TERM':'202320','CRN':'43471'},{'PRIMARY INSTRUCTOR FIRST NAME':'John','PRIMARY INSTRUCTOR LAST NAME':'Leonard'})\n\n# Fall 2024: CMSC391 is cross listed with COAR463.\n# Total enrollment 34 across two instructors (Bennett and Leonard)\n# Currently Banner shows only 20 in the JL section and doesn't mention the COAR section.\nfix(2,'Fix incorrect cross listing',{'TERM':'202410','CRN':'46263'},{'ACTUAL ENROLLMENT':34})\n\n#fix({'TERM':'202320','CRN':'43471'},{'PRIMARY INSTRUCTOR FIRST NAME':'John','PRIMARY INSTRUCTOR LAST NAME':'Leonard'})\n\n```\n:::\n\n\n### Reshape the data\n\nThe current dataframe *sections_df* contains one record per term-crn-meeting period tuple.  Within each tuple there can be up to 2 instructors.  We need to\nreshape the data with the instructors in a single column.\n\nWhile we're here we can combine instructor first and last name, and drop verbose columns.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ncols = sections_df.columns\nvalues_to_remove = ['PRIMARY INSTRUCTOR FIRST NAME','PRIMARY INSTRUCTOR LAST NAME','SECONDARY INSTRUCTOR FIRST NAME','SECONDARY INSTRUCTOR LAST NAME']\ncols = [x for x in cols if x not in values_to_remove]\n\nsections_df['ins1_last'] = sections_df['PRIMARY INSTRUCTOR LAST NAME']\nsections_df['ins1_first'] = sections_df['PRIMARY INSTRUCTOR FIRST NAME']\nsections_df['ins2_last'] = sections_df['SECONDARY INSTRUCTOR LAST NAME']\nsections_df['ins2_first'] = sections_df['SECONDARY INSTRUCTOR FIRST NAME']\nsections_df['instructor_1'] = sections_df['ins1_last']+','+sections_df['ins1_first']\nsections_df['instructor_2'] = sections_df['ins2_last']+','+sections_df['ins2_first']\nsections_df['instructor_1'].fillna('',inplace=True)\nsections_df['instructor_2'].fillna('',inplace=True)\n\nstacked_df = pd.melt(sections_df,\n    id_vars=cols,\n    value_vars=['instructor_1','instructor_2'],\n    var_name='instructor source',\n    value_name='instructor'\n)\n```\n:::\n\n\n### Clean up rows\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# remove rows with empty instructor 1.  Keep rows with empty instructor 1.\nstacked_df = stacked_df[ ~ ((stacked_df['instructor source']=='instructor_2') & (stacked_df['instructor']=='')) ]\n\n# replace any missing instructors with note\nstacked_df.loc[stacked_df[\"instructor\"].isin(['']),\"instructor\"] = stacked_df[stacked_df[\"instructor\"].isin([''])]['COURSE']+' '+stacked_df[stacked_df[\"instructor\"].isin([''])]['TERM']+' '+stacked_df[stacked_df[\"instructor\"].isin([''])]['CRN']\n\n# drop rows with zero enrollments\nstacked_df = stacked_df[stacked_df['ACTUAL ENROLLMENT']>0]\n\n# Sort the data frame so it looks pretty in the output file.\nstacked_df = stacked_df.sort_values(['TERM','DEPT','COURSE','SECT','instructor source','instructor'])\n```\n:::\n\n\n### Add additional columns\n\nWe may need the subject and the course number in the workload model analysis.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nstacked_df[\"course_subject\"] = stacked_df[\"COURSE\"].str[:4]\nstacked_df[\"course_number\"] = stacked_df[\"COURSE\"].str[4:]\n```\n:::\n\n\n### Merge persistent instructor data\n\nWe're storing some of the results in google sheets.  Further, we're using google\nsheets to store persistent data not found in the VCU course schedule report.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n# define scope\nscope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n\n# create credentials object\ncredential_file = os.path.join(os.path.expanduser(\"~\"), \".gsecrets\", \"gsheets-credentials.json\")\nif not os.path.isfile( credential_file ):\n  print(\"Missing credential file:\",credential_file)\n  sys.exit()\n\n# authorize the client\ncreds = ServiceAccountCredentials.from_json_keyfile_name(credential_file, scope)\nclient = gspread.authorize(creds)\n\nspreadsheet_key = \"1ZK7k8M85CXLof6FdeJYJuGFbfjsOXrCv5mc7OgUInWw\"\nworksheet_name = \"Instructor data\"\nsheet = client.open_by_key(spreadsheet_key).worksheet(worksheet_name)\ninstructor_df = get_as_dataframe(worksheet=sheet, evaluate_formulas=True )\n\nstacked_df = pd.merge( stacked_df,instructor_df,left_on='instructor',right_on='instructor',how='left')\n\nworksheet_name = \"Instructor notes\"\nsheet = client.open_by_key(spreadsheet_key).worksheet(worksheet_name)\ninstructor_notes_df = get_as_dataframe(worksheet=sheet, evaluate_formulas=True )\n\nstacked_df = pd.merge( stacked_df,instructor_notes_df,left_on='instructor',right_on='instructor',how='left')\n```\n:::\n\n\n### Merge persistent course data\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\n# spreadsheet_key = \"1ZK7k8M85CXLof6FdeJYJuGFbfjsOXrCv5mc7OgUInWw\" from above!\nworksheet_name = \"Course notes\"\nsheet = client.open_by_key(spreadsheet_key).worksheet(worksheet_name)\ncourse_notes_df = get_as_dataframe(worksheet=sheet, evaluate_formulas=True )\n\nstacked_df = pd.merge( stacked_df,course_notes_df,left_on='COURSE',right_on='crse',how='left')\n```\n:::\n\n\n### Identify shared rooms\n\nMany larger courses comprise of multiple CRN sharing a single classroom period.\nWe need to identify unique combinations of days of week and rooms and assign \nstore these for later aggregation.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nmeeting_cols = ['MON-IND','TUE-IND','WED-IND','THU-IND','FRI-IND','SAT-IND','SUN-IND','BEGIN TIME','END TIME','BUILDING','ROOM']\nstacked_df[\"meeting_code\"] = \"\"\nfor col in meeting_cols:\n    stacked_df[col] = stacked_df[col].fillna('.')\n    stacked_df[\"meeting_code\"] = stacked_df[\"meeting_code\"] + stacked_df[col].astype(str)\nstacked_df['meeting_id'] = pd.factorize(stacked_df['meeting_code'])[0]\n\nday_cols = ['MON-IND','TUE-IND','WED-IND','THU-IND','FRI-IND','SAT-IND','SUN-IND']\nstacked_df[\"mtgs_per_wk\"] = 0\nfor col in day_cols:\n    stacked_df[col] = stacked_df[col].fillna('.')\n    stacked_df['mtgs_per_wk'] = stacked_df[\"mtgs_per_wk\"] + (stacked_df[col] != \".\").astype(int)\n```\n:::\n\n\n### Compute appropriate aggregate measures\n\nThese measures are used in later calculations for numbers of courses, sections, instructors, etc.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n# Create various aggregate columns\nstacked_df['sum_term'] = 1.0 / stacked_df.groupby(['TERM'])['TERM'].transform('count')\nstacked_df['sum_term_crse'] = 1.0 / stacked_df.groupby(['TERM','COURSE'])['COURSE'].transform('count')\nstacked_df['sum_term_crse_crn'] = 1.0 / stacked_df.groupby(['TERM','COURSE','CRN'])['CRN'].transform('count')\nstacked_df['sum_term_crse_crn_students'] = stacked_df['ACTUAL ENROLLMENT'] * stacked_df['sum_term_crse_crn']\nstacked_df['sum_term_crse_crn_hours'] =  stacked_df['sum_term_crse_crn_students'] * stacked_df['MAX CREDITS']\n```\n:::\n\n\n### Workload model assignments\n\nThese are placeholders for any proposed workload model based on course and instructor attributes.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nstacked_df['sum_term_crse_wrkld_sample'] = 0.0\nstacked_df['sum_term_crse_wrkld_a'] = 0.0\nstacked_df['sum_term_crse_wrkld_b'] = 0.0\nstacked_df['sum_term_crse_wrkld_c'] = 0.0\n```\n:::\n\n\n### Sample workload model\n\nThis is a sample workload model.  The assigned faculty workoad will be stored in the *sum_term_crse_wrklod_sample* field.  Here is the model:\n\n1. Each section/CRN is worth a full teaching credit.\n1. Research, indepedent study and coop/intern sections receive zero teaching credit in this workload model.  Instructors receive *credit* through their salary if they're staff.  Research active faculty get reduced teaching loads.\n1. Lab sections including actual course labs, capstone/senior design, and VIP receive 1/3 credit.  This is consistent with the model that 3 lab hours is equivalent to 1 teaching hour. (e.g., 3-3-4 courses.)\nNOTE that laboratory sections are NOT coded as separate labs, rather they are coded as LEC making it\ndifficult to discern these.  See EGRE306 for an example.\n1. Seminar sections get full section credit as a positive incentive. There is a limited number of SEM courses, they are important to the curriculum, and we want them covered.\n1. CRSE are adjusted \n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n# Assign standard CRN : One CRN/section per teaching course\nstacked_df['sum_term_crse_wrkld_sample'] = stacked_df[\"sum_term_crse_crn\"]\n\n# Adjust these courses by shared offerings, classes with different CRN taught \n# by the same instructor in the same room/period\nstacked_df['sum_term_crse_wrkld_sample'] = stacked_df['sum_term_crse_wrkld_sample'] / stacked_df.groupby(['TERM','instructor','meeting_id'])['meeting_id'].transform('count')\n\n# For specific courses, if we see a meeting time with only one day per week then this is a lab section\n# indepedent of the CRN.  We'll adjust them to LAB sections, then let the logic below\n# code them as 1/3 credit, or whatever a lab section should get.\n\ncourses_with_labs = ['EGRE306']\nfor course in courses_with_labs:\n    stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['mtgs_per_wk']==1),'TYPE'] = 'LAB'\n\n# Exclude teaching credit for research (RES), independent study (IND), and intern/coop (FLD).\n# Credit is given for these activities in reduced teaching (research active) or summer pay.\nstacked_df.loc[stacked_df['TYPE'].isin(['RES','IND','FLD']),'sum_term_crse_wrkld_sample'] = 0.0\n\n# Reassign LAB 1/3 of CRN.  Labs include capstone, regular lab sections, and VIP\nstacked_df.loc[stacked_df['TYPE'].isin(['LAB']),'sum_term_crse_wrkld_sample'] = stacked_df.loc[stacked_df['TYPE'].isin(['LAB']),'sum_term_crse_wrkld_sample'] / 3.0\n\n# Ensure that SEM get full credit because we want to reward the faculty member for doing it!\nstacked_df.loc[stacked_df['TYPE'].isin(['SEM']),'sum_term_crse_wrkld_sample'] = stacked_df.loc[stacked_df['TYPE'].isin(['SEM']),'sum_term_crse_wrkld_sample'] / 1.0\n```\n:::\n\n\n### Store the data for later use\n\nWe're storing both the stacked and unstacked data.  Note that the\naggregate measures are stored with the stacked data only.\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n# Store as CSV files\nsections_df.to_csv('sections_df.csv', index=False)\nstacked_df.to_csv('stacked_df.csv', index=False)\n```\n:::\n\n\n### Store the data in google sheets\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\n# Open the worksheet \nspreadsheet_key = \"1ZK7k8M85CXLof6FdeJYJuGFbfjsOXrCv5mc7OgUInWw\"\nworksheet_name = \"Source data\"\n\ndata_to_write = stacked_df.to_records(index=False)\ntry:\n    sheet = client.open_by_key(spreadsheet_key).worksheet(worksheet_name)\nexcept:\n    sheet = client.open_by_key(spreadsheet_key).add_worksheet( \n        title = worksheet_name,nrows=100,ncols=10\n    )\nsheet.clear()\nset_with_dataframe(worksheet=sheet, dataframe=stacked_df, include_index=False,include_column_header=True, resize=True)\n```\n:::\n\n\n### Freshen persistent instructor data\n\nThis block identifies any instructors not found in the persistent instructor data\nand adds them to the list with default values.\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\n#worksheet_name = \"Instructor data\"\n#summary_df = stacked_df.groupby('instructor')[['COLLEGE','DEPT']].apply(lambda x: x.mode().iloc[0]).#reset_index()\n#summary_df = summary_df.sort_values(by=['COLLEGE','DEPT','instructor'])\n#data_to_write = summary_df.to_records(index=False)\n#try:\n#    sheet = client.open_by_key(spreadsheet_key).worksheet(worksheet_name)\n#except:\n#    nrows,ncols = summary_df.shape\n#    sheet = client.open_by_key(spreadsheet_key).add_worksheet( \n#        title = worksheet_name,rows=nrows+1,cols=ncols+1\n#    )\n#sheet.clear()\n#set_with_dataframe(worksheet=sheet, dataframe=summary_df, include_index=False,include_column_header=True, resize=True)\n\n# Find names in df2 that are not in df1\n##names_to_add = df2[~df2['name'].isin(df1['name'])]\n\n# Add the rows with missing names from df2 to df1\n## df1 = pd.concat([df1, names_to_add], ignore_index=True)\n```\n:::\n\n\n",
    "supporting": [
      "clean_files"
    ],
    "filters": [],
    "includes": {}
  }
}