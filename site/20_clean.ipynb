{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Cleaning the data\n",
        "---"
      ],
      "id": "8ef0ff84"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This script describes the data and walks through a process of data cleaning.\n",
        "\n",
        "At completion of this script all the individual semester data files will be combined into a single dataframe for analysis, and the dataframe will be refactored for cleaner analysis.\n",
        "\n",
        "TLDR: Here is a link to the [cleaned dataframe](stacked_df.csv).  This dataframe contains one tuple per (TERM,CRN,INSTRUCTOR,MEETING_CODE).\n",
        "\n",
        "TLDR: Here is a link to the [google sheet](https://docs.google.com/spreadsheets/d/1ZK7k8M85CXLof6FdeJYJuGFbfjsOXrCv5mc7OgUInWw/edit#gid=1484314377) with the cleaned data loaded \n",
        "in the \"source data\" tab and other sheets referencing the source data.\n",
        "\n",
        "## Data sources\n",
        "\n",
        "The files are named appropriately and stored in the *data* folder in this repository.\n"
      ],
      "id": "daee316e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import gspread\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from math import ceil\n",
        "from tabulate import tabulate\n",
        "from IPython.display import Markdown\n",
        "from gspread_dataframe import set_with_dataframe, get_as_dataframe\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "\n",
        "directory_path = './data'\n",
        "file_list = os.listdir(directory_path)\n",
        "xlsx_files = [file for file in file_list if file.endswith('.xlsx')]\n",
        "xlsx_df = pd.DataFrame({'file_name':xlsx_files})\n",
        "\n",
        "xlsx_df['term_code'] = xlsx_df['file_name'].str.split('-').str[2]\n",
        "\n",
        "def convert_ay(term_code):\n",
        "    year = term_code[2:4]\n",
        "    return f'AY{int(year)-1}-{year}'\n",
        "\n",
        "xlsx_df['academic_year'] = xlsx_df['term_code'].apply(convert_ay)\n",
        "\n",
        "xlsx_df['period_code'] = xlsx_df['file_name'].str.split('-').str[3]\n",
        "xlsx_df['period_code'] = xlsx_df['period_code'].str.split('.').str[0]\n",
        "\n",
        "def convert_period(period_code):\n",
        "    year = period_code[2:]\n",
        "    period_id = period_code[:2]\n",
        "    terms = {'FA': 'Fall', 'SP': 'Spring', 'SU': 'Summer'}\n",
        "    period_name = terms.get(period_id, 'Unknown')\n",
        "    return f'{period_name} {year}'\n",
        "\n",
        "xlsx_df['period_name'] = xlsx_df['period_code'].apply(convert_period)\n",
        "\n",
        "xlsx_df[\"url\"] = \"<a href='data/\"+xlsx_df[\"file_name\"]+\"'>\"+xlsx_df[\"file_name\"]+\"</a>\"\n",
        "\n",
        "Markdown(tabulate(\n",
        "  xlsx_df[['url','term_code','academic_year','period_code','period_name']], \n",
        "  headers=['File name','Term Code','Acad Year','Period Code','Period Name'],\n",
        "  numalign=\"left\",stralign=\"left\",\n",
        "  showindex=False\n",
        "))\n",
        "\n",
        "xlsx_df = xlsx_df[['file_name','term_code','academic_year','period_code','period_name']]"
      ],
      "id": "f4b5dc3c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning\n",
        "\n",
        "The following sections combine the individual sources of data and clean them up.\n",
        "\n",
        "### Combining to single data frame\n",
        "\n",
        "The following section combines each XLSX into a single data frame.  The contents of the files are variable in length depending on the number of sections taught\n",
        "during any given semester.\n",
        "\n",
        "The appropriate block starts one row after the row with the keyword *TERM* in the first column, denoting the header row.  The appropriate block ends with the row prior to the row with the keyword *N =*. \n",
        "\n",
        "We're assuming that all xlsx workbooks share the same columns and names.\n"
      ],
      "id": "84383c38"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| \n",
        "# Initialize an empty list to store trimmed DataFrames\n",
        "trimmed_dfs = []\n",
        "\n",
        "# Iterate through the list of XLSX file names\n",
        "for file_name in xlsx_df['file_name']:\n",
        "    # Load the XLSX file into a DataFrame\n",
        "    full_path = os.path.join(directory_path, file_name)\n",
        "    df = pd.read_excel(full_path)\n",
        "    \n",
        "    # Find the row index where \"TERM\" is in the first column\n",
        "    term_index = df.index[df.iloc[:, 0] == \"TERM\"].tolist()[0]\n",
        "    \n",
        "    # Find the row index where \"N=\" is in the first column\n",
        "    n_index = df.index[df.iloc[:, 0].str.startswith(\"N =\").fillna(False)].tolist()[0]\n",
        "\n",
        "    # Clip the desired block and add column names\n",
        "    trimmed_df = df.loc[term_index + 1 : n_index - 1]\n",
        "    trimmed_df.columns = df.iloc[term_index].values\n",
        "\n",
        "    # Append the trimmed DataFrame to the list\n",
        "    trimmed_dfs.append(trimmed_df)\n",
        "\n",
        "# Combine the individual dataframes into one big one.\n",
        "sections_df = pd.concat(trimmed_dfs, ignore_index=True)"
      ],
      "id": "63b121b0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Merge in the term and period data from the xlsx_df dataframe\n",
        "\n",
        "The following code merges in the term and period data with the section data.\n",
        "First ensure that the key columns are strings, then merge away.\n"
      ],
      "id": "61be38d8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sections_df['SECT'] = sections_df['SECT'].astype(str)\n",
        "sections_df['TERM'] = sections_df['TERM'].astype(str)\n",
        "xlsx_df['term_code'] = xlsx_df['term_code'].astype(str)\n",
        "sections_df = pd.merge(sections_df,xlsx_df,left_on='TERM', right_on='term_code', how='left')"
      ],
      "id": "01882352",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fix known errors\n",
        "\n",
        "The data in Banner doesn't always reflect reality.  This step corrects\n",
        "known errors in the data.\n",
        "\n",
        "Note that the section data are stored one row per term-crn-meeting period.\n",
        "\n",
        "The purpose of this section is to demonstrate an auditable process for documenting\n",
        "changes to the source data.\n",
        "\n",
        "There is nothing magic about the changes below.  As I shared the data with others, they found that\n",
        "the banner data did not reflect reality.  For this workload analysis we want the data to reflect\n",
        "reality, so we fix it.\n",
        "\n",
        "Additional fixes are expected to be added as new eyes look at their data.\n"
      ],
      "id": "dd388747"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "# Ensure that columns TERM and CRN are strings to help with lookup.\n",
        "\n",
        "sections_df['TERM'] = sections_df['TERM'].astype(str)\n",
        "sections_df['CRN'] = sections_df['CRN'].astype(str)\n",
        "\n",
        "sections_df[\"fixes\"] = \"\"\n",
        "sections_df[\"fix_notes\"] = \"\"\n",
        "\n",
        "# A helper function to correct data.\n",
        "\n",
        "def fix_sections( id, note, key, data ):\n",
        "    for item in data.keys():\n",
        "        sections_df.loc[(sections_df[\"TERM\"]==key[\"TERM\"])&(sections_df[\"CRN\"]==key[\"CRN\"]),item]=data[item]\n",
        "    sections_df.loc[(sections_df[\"TERM\"]==key[\"TERM\"])&(sections_df[\"CRN\"]==key[\"CRN\"]),\"fixes\"] += f\";FIX{id:03}\"\n",
        "    sections_df.loc[(sections_df[\"TERM\"]==key[\"TERM\"])&(sections_df[\"CRN\"]==key[\"CRN\"]),\"fix_notes\"] += \";\" + note"
      ],
      "id": "6cdfa164",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Spring 2023: CMSC475 John Leonard taught for David Shepherd\n",
        "fix_sections(1,'Swap Leonard for Shepherd',{'TERM':'202320','CRN':'43471'},{'PRIMARY INSTRUCTOR FIRST NAME':'John','PRIMARY INSTRUCTOR LAST NAME':'Leonard'})\n",
        "\n",
        "# Fall 2024: CMSC391 is cross listed with COAR463.\n",
        "# Total enrollment 34 across two instructors (Bennett and Leonard)\n",
        "# Currently Banner shows only 20 in the JL section and doesn't mention the COAR section.\n",
        "fix_sections(2,'Fix incorrect cross listing',{'TERM':'202410','CRN':'46263'},{'ACTUAL ENROLLMENT':34})\n",
        "\n",
        "fix_sections(3,\"Remove Duke as 2nd instructor\",{'TERM':'202410','CRN':'40553'},{'SECONDARY INSTRUCTOR FIRST NAME':'','SECONDARY INSTRUCTOR LAST NAME':''})\n",
        "fix_sections(4,\"Remove Duke as 2nd instructor\",{'TERM':'202410','CRN':'40554'},{'SECONDARY INSTRUCTOR FIRST NAME':'','SECONDARY INSTRUCTOR LAST NAME':''})\n",
        "fix_sections(5,\"Remove Duke as 2nd instructor\",{'TERM':'202410','CRN':'40555'},{'SECONDARY INSTRUCTOR FIRST NAME':'','SECONDARY INSTRUCTOR LAST NAME':''})\n",
        "\n",
        "fix_sections(6,\"Remove Sparks as 2nd instructor\",{'TERM':'202320','CRN':'17442'},{'SECONDARY INSTRUCTOR FIRST NAME':'','SECONDARY INSTRUCTOR LAST NAME':''})\n",
        "fix_sections(7,\"Remove Duke as 2nd instructor\",{'TERM':'202320','CRN':'33698'},{'SECONDARY INSTRUCTOR FIRST NAME':'','SECONDARY INSTRUCTOR LAST NAME':''})\n",
        "fix_sections(8,\"Remove Duke as 2nd instructor\",{'TERM':'202320','CRN':'41891'},{'SECONDARY INSTRUCTOR FIRST NAME':'','SECONDARY INSTRUCTOR LAST NAME':''})\n",
        "fix_sections(9,\"Capstone common course is LEC not SEM\",{'TERM':'202320','CRN':'45290'},{'TYPE':'LEC'})"
      ],
      "id": "579ee411",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reshape the data\n",
        "\n",
        "The current dataframe [sections_df](sections_df.csv) contains one record per term-crn-meeting period tuple.  Within each tuple there can be up to 2 instructors.  We need to reshape the data with the instructors in a single column.\n",
        "\n",
        "While we're here we can combine instructor first and last name, and drop verbose columns.\n"
      ],
      "id": "6d9564b7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cols = sections_df.columns\n",
        "values_to_remove = ['PRIMARY INSTRUCTOR FIRST NAME','PRIMARY INSTRUCTOR LAST NAME','SECONDARY INSTRUCTOR FIRST NAME','SECONDARY INSTRUCTOR LAST NAME']\n",
        "cols = [x for x in cols if x not in values_to_remove]\n",
        "\n",
        "sections_df['ins1_last'] = sections_df['PRIMARY INSTRUCTOR LAST NAME']\n",
        "sections_df['ins1_first'] = sections_df['PRIMARY INSTRUCTOR FIRST NAME']\n",
        "sections_df['ins2_last'] = sections_df['SECONDARY INSTRUCTOR LAST NAME']\n",
        "sections_df['ins2_first'] = sections_df['SECONDARY INSTRUCTOR FIRST NAME']\n",
        "sections_df['instructor_1'] = sections_df['ins1_last']+sections_df['ins1_first'].apply(lambda x: ',' if x != \"\" else \"\")+sections_df['ins1_first']\n",
        "sections_df['instructor_2'] = sections_df['ins2_last']+sections_df['ins2_first'].apply(lambda x: ',' if x != \"\" else \"\")+sections_df['ins2_first']\n",
        "sections_df['instructor_1'].fillna('',inplace=True)\n",
        "sections_df['instructor_2'].fillna('',inplace=True)\n",
        "\n",
        "stacked_df = pd.melt(sections_df,\n",
        "    id_vars=cols,\n",
        "    value_vars=['instructor_1','instructor_2'],\n",
        "    var_name='instructor source',\n",
        "    value_name='instructor'\n",
        ")"
      ],
      "id": "546817c7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clean up rows\n",
        "\n",
        "The process above introduces records with missing instructor_2.  This\n",
        "code removes records missing instructor_2.\n"
      ],
      "id": "38fc577b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# remove rows with empty instructor 1.  Keep rows with empty instructor 1.\n",
        "stacked_df = stacked_df[ ~ ((stacked_df['instructor source']=='instructor_2') & (stacked_df['instructor']=='')) ]"
      ],
      "id": "8799e1e2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In some summer courses an instructor was not listed in the data.  An instructor\n",
        "name is generated using the course and semester. This can be cleaned later.\n"
      ],
      "id": "67e92a0e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# replace any missing instructors with note\n",
        "stacked_df.loc[stacked_df[\"instructor\"].isin(['']),\"instructor\"] = stacked_df[stacked_df[\"instructor\"].isin([''])]['COURSE']+' '+stacked_df[stacked_df[\"instructor\"].isin([''])]['TERM']+' '+stacked_df[stacked_df[\"instructor\"].isin([''])]['CRN']"
      ],
      "id": "391311cb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some sections, for example RES sections or cancelled sections have zero enrollments. These are removed, keeping only sections with positive enrollments.\n"
      ],
      "id": "077a0f30"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# drop rows with zero enrollments\n",
        "stacked_df = stacked_df[stacked_df['ACTUAL ENROLLMENT']>0]"
      ],
      "id": "fdb55ea5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "While not necessary, the resulting dataframe can be sorted so that it looks\n",
        "pretty when saved to a CSV.\n"
      ],
      "id": "6a7ac319"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sort the data frame so it looks pretty in the output file.\n",
        "stacked_df = stacked_df.sort_values(['TERM','DEPT','COURSE','SECT','instructor source','instructor'])"
      ],
      "id": "d60d9b72",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Add additional data columns\n",
        "\n",
        "We may need the subject and the course number in the workload model analysis.\n"
      ],
      "id": "f6500d29"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "stacked_df[\"course_subject\"] = stacked_df[\"COURSE\"].str[:4]\n",
        "stacked_df[\"course_number\"] = stacked_df[\"COURSE\"].str[4:]"
      ],
      "id": "b1e1069a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For each section, add a new field with the count of instructors sharing\n",
        "this section.  This helps with workload and other computations later.\n"
      ],
      "id": "d74cac85"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Number of instructors sharing a common CRN.\n",
        "stacked_df[\"instructor_cnt\"] = stacked_df.groupby(['TERM','COURSE','CRN'])['CRN'].transform('count') / stacked_df.groupby(['TERM','COURSE','CRN','instructor'])['instructor'].transform('count') \n",
        "\n",
        "stacked_df[\"capstone_cnt\"] = 0.0  # used downstream to provide an actual capstone count rather than an estimated count of capstone sections."
      ],
      "id": "189aabf8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It's getting old adding new columns, then having to rework the formuluas in the rather brittle google sheet.  I'm adding a few spare columns here to be used as necessary.  This is the best place to add the new columns, just prior to the calculation of the aggregate measures and workload attributes.\n"
      ],
      "id": "d8077a2b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "stacked_df[\"lec_only_course_list\"] = \"\"\n",
        "stacked_df[\"spare_col_2\"] = 0\n",
        "stacked_df[\"spare_col_3\"] = 0\n",
        "stacked_df[\"spare_col_4\"] = 0\n",
        "stacked_df[\"spare_col_5\"] = 0\n",
        "stacked_df[\"spare_col_6\"] = 0"
      ],
      "id": "2e1faa6b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Merge persistent instructor data\n",
        "\n",
        "The Banner report that we're using for this analysis does not include all the necessary data\n",
        "for a proper analysis.  The report infers the offering department of the course (e.g., ENGR497 or CMSC475), but not the home department of the instructor.  For example, capstone courses are coded ad ENGR497, but\n",
        "the record won't include the home department of the instructor, making it difficult to roll up all the courses\n",
        "by home department of the instructor.\n",
        "\n",
        "We store persistent instructor and course data in a separate google sheet.  As these persistent data are\n",
        "changed or corrected, this analysis should be regenerated to use these amended data.\n",
        "\n",
        "The code below merges the [persistent instructor data](https://docs.google.com/spreadsheets/d/1ZK7k8M85CXLof6FdeJYJuGFbfjsOXrCv5mc7OgUInWw/edit#gid=654840116) from the google sheet into the working dataframe.\n"
      ],
      "id": "b7a5aa35"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# define scope\n",
        "scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
        "\n",
        "# create credentials object\n",
        "credential_file = os.path.join(os.path.expanduser(\"~\"), \".gsecrets\", \"gsheets-credentials.json\")\n",
        "if not os.path.isfile( credential_file ):\n",
        "  print(\"Missing credential file:\",credential_file)\n",
        "  sys.exit()\n",
        "\n",
        "# authorize the client\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name(credential_file, scope)\n",
        "client = gspread.authorize(creds)\n",
        "\n",
        "spreadsheet_key = \"1ZK7k8M85CXLof6FdeJYJuGFbfjsOXrCv5mc7OgUInWw\"\n",
        "worksheet_name = \"Instructor data\"\n",
        "sheet = client.open_by_key(spreadsheet_key).worksheet(worksheet_name)\n",
        "instructor_df = get_as_dataframe(worksheet=sheet, evaluate_formulas=True )\n",
        "\n",
        "stacked_df = pd.merge( stacked_df,instructor_df,left_on='instructor',right_on='instructor',how='left')\n",
        "\n",
        "worksheet_name = \"Instructor notes\"\n",
        "sheet = client.open_by_key(spreadsheet_key).worksheet(worksheet_name)\n",
        "instructor_notes_df = get_as_dataframe(worksheet=sheet, evaluate_formulas=True )\n",
        "\n",
        "stacked_df = pd.merge( stacked_df,instructor_notes_df,left_on='instructor',right_on='instructor',how='left')"
      ],
      "id": "cb78a478",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Merge persistent course data\n",
        "\n",
        "[Persistent course data](https://docs.google.com/spreadsheets/d/1ZK7k8M85CXLof6FdeJYJuGFbfjsOXrCv5mc7OgUInWw/edit#gid=498592034) is also stored in the google sheet and merged with the working dataframe.\n"
      ],
      "id": "a7bab590"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# spreadsheet_key = \"1ZK7k8M85CXLof6FdeJYJuGFbfjsOXrCv5mc7OgUInWw\" from above!\n",
        "worksheet_name = \"Course notes\"\n",
        "sheet = client.open_by_key(spreadsheet_key).worksheet(worksheet_name)\n",
        "course_notes_df = get_as_dataframe(worksheet=sheet, evaluate_formulas=True )\n",
        "\n",
        "stacked_df = pd.merge( stacked_df,course_notes_df,left_on='COURSE',right_on='crse',how='left')"
      ],
      "id": "3a687c74",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Identify shared rooms\n",
        "\n",
        "Some CRN share the same classroom and instructor.  Examples might include an UG and GR section sharing\n",
        "the same lecture, or multiple LEC/LAB combos sharing the same LEC with different LAB rooms and time.\n",
        "\n",
        "To properly identify shared lectures we need to identify unique combinations of days of week and rooms and assign store these values for later aggregation.\n"
      ],
      "id": "250408b6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "time_cols = ['MON-IND','TUE-IND','WED-IND','THU-IND','FRI-IND','SAT-IND','SUN-IND','BEGIN TIME','END TIME']\n",
        "room_cols = ['BUILDING','ROOM']\n",
        "\n",
        "stacked_df[\"time_code\"] = \"\"\n",
        "for col in time_cols:\n",
        "    stacked_df[col] = stacked_df[col].fillna('.')\n",
        "    stacked_df[\"time_code\"] = stacked_df[\"time_code\"] + stacked_df[col].astype(str)\n",
        "stacked_df['time_id'] = pd.factorize(stacked_df['time_code'])[0]\n",
        "\n",
        "stacked_df[\"room_code\"] = \"\"\n",
        "for col in room_cols:\n",
        "    stacked_df[col] = stacked_df[col].fillna('.')\n",
        "    stacked_df[\"room_code\"] = stacked_df[\"room_code\"] + stacked_df[col].astype(str)\n",
        "stacked_df['room_id'] = pd.factorize(stacked_df['room_code'])[0]\n",
        "\n",
        "stacked_df[\"meeting_code\"] = stacked_df[\"room_code\"] + stacked_df[\"time_code\"]\n",
        "stacked_df['meeting_id'] = pd.factorize(stacked_df['meeting_code'])[0]\n",
        "\n",
        "day_cols = ['MON-IND','TUE-IND','WED-IND','THU-IND','FRI-IND','SAT-IND','SUN-IND']\n",
        "stacked_df[\"mtgs_per_wk\"] = 0\n",
        "for col in day_cols:\n",
        "    stacked_df[col] = stacked_df[col].fillna('.')\n",
        "    stacked_df['mtgs_per_wk'] = stacked_df[\"mtgs_per_wk\"] + (stacked_df[col] != \".\").astype(int)\n",
        "\n",
        "stacked_df[\"BEGIN TIME\"] = stacked_df[\"BEGIN TIME\"].replace(\".\",\"0\")\n",
        "stacked_df[\"END TIME\"] = stacked_df[\"END TIME\"].replace(\".\",\"0\")\n",
        "stacked_df['mtg_length'] = stacked_df[\"END TIME\"].astype(int) - stacked_df[\"BEGIN TIME\"].astype(int)\n",
        "\n",
        "stacked_df['shared_mtgs_cnt'] =  stacked_df.groupby(['TERM','instructor','time_id'])['time_id'].transform('count')\n",
        "stacked_df.loc[(stacked_df['time_code'].isin(['.........'])),'shared_mtgs_cnt'] = 1\n",
        "\n",
        "stacked_df['mtgs_per_crn'] =  stacked_df.groupby(['TERM','CRN','instructor'])['CRN'].transform('count')"
      ],
      "id": "1a213bee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Find all courses taught by same instructor at the same time\n",
        "\n",
        "This code builds a list of separate courses taught by an instructor at the same time. This code\n",
        "is similar to the code above with the enhancement that it produces an explicit list of courses\n",
        "that share the same room and time.\n"
      ],
      "id": "fe491667"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def concat_courses(group):\n",
        "    return ','.join(group['COURSE'])\n",
        "\n",
        "temp_df = pd.DataFrame();\n",
        "keys = ['TERM','instructor','time_code']\n",
        "temp_df[\"concat\"] = stacked_df.groupby(keys).apply(concat_courses)\n",
        "temp_df[\"list\"] = temp_df[\"concat\"].apply( lambda x :  list(set(x.split(\",\"))) )\n",
        "temp_df[\"combined_count\"] = temp_df[\"list\"].apply( lambda x :  len(x) )\n",
        "temp_df[\"combined_sections\"] = temp_df[\"list\"].apply( lambda x :  \",\".join(x) )\n",
        "temp_df = temp_df.reset_index()\n",
        "temp_df = temp_df[ (temp_df['time_code']!='.........')&(temp_df['combined_count']>1)]\n",
        "temp_df = temp_df[['TERM','instructor','time_code','combined_count','combined_sections']]\n",
        "stacked_df = pd.merge(stacked_df,temp_df,left_on=keys, right_on=keys,how=\"left\")"
      ],
      "id": "1f3e9ab0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CGEP: convert to IND rather than LEC from workload perspective\n",
        "\n",
        "[Cardinal Education](https://www.cardinaleducation.org/) (formally known as the [Commonwealth Graduate Engineering Program (CGEP)](https://cgep.vcu.edu/)) is a collaborative effort among six participating universities and institutions throughout the Commonwealth of Virginia. It utilizes virtual learning classrooms and education technology in synchronous and asynchronous formats to provide working engineers the opportunity to earn a master's degree in engineering from any of the six participating universities/institutions.\n",
        "\n",
        "CGEP courses hosted at VCU are coded as LEC in Banner and must be associated with a VCU instructor. This ensures that the student receives proper credit towards graduation.  However, from a workload perspective, these courses do not require local instructor preparation or teaching effort.\n",
        "\n",
        "This section recodes CGEP courses to independent study (IND).\n"
      ],
      "id": "4c3a4846"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Function to set the 'TYPE' column based on a string search in 'TITLE'\n",
        "def set_type_based_on_search(row):\n",
        "    title = row['TITLE']\n",
        "    newtype = row['TYPE']\n",
        "    if 'CGEP' in title:\n",
        "        newtype = 'IND'\n",
        "    return newtype\n",
        "\n",
        "# Apply the function to the entire DataFrame\n",
        "stacked_df['TYPE'] = stacked_df.apply(set_type_based_on_search, axis=1)"
      ],
      "id": "a38f4987",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that additional spare columns are added to persistent instructor and course google sheets.\n",
        "\n",
        "### Compute appropriate aggregate measures\n",
        "\n",
        "These measures are used in later calculations for numbers of courses, sections, instructors, etc.\n",
        "\n",
        "These computations are normalized to the appropriate group so that they sum to the correct values when aggregated at the specified group level.\n"
      ],
      "id": "62bcd392"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create various aggregate columns\n",
        "stacked_df['sum_term'] = 1.0 / stacked_df.groupby(['TERM'])['TERM'].transform('count')\n",
        "stacked_df['sum_term_crse'] = 1.0 / stacked_df.groupby(['TERM','COURSE'])['COURSE'].transform('count')\n",
        "stacked_df['sum_term_crse_crn'] = 1.0 / stacked_df.groupby(['TERM','COURSE','CRN','time_code'])['CRN'].transform('count') / stacked_df['mtgs_per_crn']\n",
        "stacked_df['sum_term_crse_crn_mtg_students'] = stacked_df['ACTUAL ENROLLMENT'] * stacked_df['sum_term_crse_crn'] * stacked_df['mtgs_per_crn']\n",
        "stacked_df['sum_term_crse_crn_hours'] =  stacked_df['sum_term_crse_crn_mtg_students'] * stacked_df['MAX CREDITS']  / stacked_df['mtgs_per_crn']"
      ],
      "id": "5a790ca9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Placeholder Workload model assignments\n",
        "\n",
        "These are placeholders for any proposed workload model based on course and instructor attributes.\n",
        "\n",
        "For each workload model, there is a:\n",
        "\n",
        "* *sum_term_crse_wrkld* containing the numeric assignment of workload for that entry in the dataframe.\n",
        "* *wrkld_*_type* containing the recoded course type.  For example, some LEC sections that are actually labs are coded labs. Capstones are also highlighted.\n",
        "* *wrkld_note* containing a note about the specific workload assignment.\n"
      ],
      "id": "a74db290"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "stacked_df['wrkld_sample_type'] = stacked_df['TYPE']\n",
        "stacked_df['sum_term_crse_wrkld_sample'] = 0.0\n",
        "stacked_df['sum_term_crse_wrkld_sample_lec'] = 0.0\n",
        "stacked_df['wrkld_sample_note'] = \"\"\n",
        "stacked_df['wrkld_a_type'] = stacked_df['TYPE']\n",
        "stacked_df['sum_term_crse_wrkld_a'] = 0.0\n",
        "stacked_df['sum_term_crse_wrkld_a_lec'] = 0.0\n",
        "stacked_df['wrkld_a_note'] = \"\"\n",
        "stacked_df['wrkld_b_type'] = stacked_df['TYPE']\n",
        "stacked_df['sum_term_crse_wrkld_b'] = 0.0\n",
        "stacked_df['sum_term_crse_wrkld_b_lec'] = 0.0\n",
        "stacked_df['wrkld_b_note'] = \"\"\n",
        "stacked_df['wrkld_c_type'] = stacked_df['TYPE']\n",
        "stacked_df['sum_term_crse_wrkld_c'] = 0.0\n",
        "stacked_df['sum_term_crse_wrkld_c_lec'] = 0.0\n",
        "stacked_df['wrkld_c_note'] = \"\""
      ],
      "id": "a116fd57",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample workload model\n",
        "\n",
        "This is the sample workload model.  The assigned faculty workoad will be stored in the *sum_term_crse_wrklod_sample* field.  Here is the model:\n"
      ],
      "id": "3a78e628"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_sample = {\n",
        "    'base_lecture_value':1.0,\n",
        "    'labs_per_lecture':3.0,\n",
        "    'vips_per_lecture':3.0,\n",
        "    'capstones_per_lecture': 3.0,\n",
        "    'students_per_capstone': 4.0,\n",
        "    'seminars_per_lecture': 1.0,\n",
        "    'res_ind_fld_per_lecture': 0.0,\n",
        "    'large_classes': [ [80,1.5],[160,2.0],[240,2.5] ]\n",
        "}"
      ],
      "id": "a12f9715",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Each section/CRN is worth a full teaching credit.\n",
        "1. Research, indepedent study and coop/intern sections receive zero teaching credit in this workload model.  Instructors receive *credit* through their salary if they're staff.  Research active faculty get reduced teaching loads.\n",
        "1. Lab sections including actual course labs, capstone/senior design, and VIP receive 1/3 credit.  This is consistent with the model that 3 lab hours is equivalent to 1 teaching hour. (e.g., 3-3-4 courses.)\n",
        "NOTE that laboratory sections are NOT coded as separate labs, rather they are coded as LEC making it\n",
        "difficult to discern these.  See EGRE306 for an example.\n",
        "1. Seminar sections get full section credit as a positive incentive. There is a limited number of SEM courses, they are important to the curriculum, and we want them covered.\n",
        "1. Capstone designs are scaled to give one LAB (0.33 per above) unit per groups of 4 students.\n",
        "\n",
        "\n",
        "### Assign BASE workload to all sections\n",
        "\n",
        "Assign base workload to all records. All sections independent of section type start with a base workload of 1.\n",
        "\n",
        "Adjust base workload for courses shared by multiple instructors.\n",
        "\n",
        "In some cases, a shared instructor was included in Banner so that the shared instructor could monitor the \n",
        "course in Canvas only, without offering additional teaching effort.  In these cases, I recommend\n",
        "adding a \"FIX\" (listed above) to remove the secondary instructor from the workload data,\n",
        " ensuring that they don't get credit for a class they aren't actually co-teaching.\n"
      ],
      "id": "4895f35b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Assign standard workload : One teaching course shared across multiple instructors\n",
        "stacked_df[\"sum_term_crse_wrkld_sample\"] = model_sample['base_lecture_value']\n",
        "# Update note\n",
        "stacked_df.loc[(stacked_df['wrkld_sample_type']=='LEC'),'wrkld_sample_note'] = \"BASE: [wrkld] \"\n",
        "\n",
        "# Adjust for multiple instructors\n",
        "stacked_df[\"sum_term_crse_wrkld_sample\"] = stacked_df[\"sum_term_crse_wrkld_sample\"] / stacked_df[\"instructor_cnt\"]\n",
        "# Update note\n",
        "stacked_df.loc[(stacked_df['wrkld_sample_type']=='LEC')&(stacked_df['instructor_cnt']>1.0),'wrkld_sample_note'] = \"BASE: [wrkld] / (2 co-teaching) \""
      ],
      "id": "3d37aa19",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adjust for courses taught at same time by same instructor\n"
      ],
      "id": "ce2d159e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "# Adjust for combined lectures (this code is deprecated for a smarter logic)\n",
        "\n",
        "if(0):\n",
        "    stacked_df.loc[(stacked_df['wrkld_sample_type']=='LEC')&(stacked_df['combined_count']>1),'sum_term_crse_wrkld_sample'] = stacked_df.loc[(stacked_df['wrkld_sample_type']=='LEC')&(stacked_df['combined_count']>1),'sum_term_crse_wrkld_sample'] / stacked_df.loc[(stacked_df['wrkld_sample_type']=='LEC')&(stacked_df['combined_count']>1),'combined_count'] \n",
        "\n",
        "    stacked_df.loc[(stacked_df['wrkld_sample_type']=='LEC')&(stacked_df['combined_count']>1),'wrkld_sample_note'] = stacked_df.loc[(stacked_df['wrkld_sample_type']=='LEC')&(stacked_df['combined_count']>1),'wrkld_sample_note'] + \": combined(\"+stacked_df.loc[(stacked_df['wrkld_sample_type']=='LEC')&(stacked_df['combined_count']>1),'combined_sections']+\")\""
      ],
      "id": "cec8e9ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# adjust workload for CRN sharing same teaching time\n",
        "stacked_df.loc[(stacked_df['shared_mtgs_cnt']>1),'sum_term_crse_wrkld_sample'] = stacked_df.loc[(stacked_df['shared_mtgs_cnt']>1),'sum_term_crse_wrkld_sample'] / stacked_df.loc[(stacked_df['shared_mtgs_cnt']>1),'shared_mtgs_cnt'] \n",
        "\n",
        "# Update note to reflect adjustment\n",
        "stacked_df.loc[(stacked_df['shared_mtgs_cnt']>1),'wrkld_sample_note'] = (\n",
        "  stacked_df.loc[(stacked_df['shared_mtgs_cnt']>1),'wrkld_sample_note'] + \"/ \" + \n",
        "  stacked_df.loc[(stacked_df['shared_mtgs_cnt']>1),'shared_mtgs_cnt'].astype(str) +\" CRN at same time\"\n",
        ")"
      ],
      "id": "e2638576",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adjust for capstone workloads\n",
        "\n",
        "Capstone / senior design courses are coded differently in each department within the college. Further, some of these\n",
        "course numbers change over time (across semesters).\n",
        "\n",
        "A list of capstone courses was assembled manually and then applied to convert the capstone sections to CAP.\n",
        "\n",
        "This code is applied in two steps with an opportunity to introduce adjustments to the estimate of capstones.\n",
        "\n",
        "In this sample workload model, estimates of the number of capstones are rounded up (CEIL) to the next highest integer number of capstones.\n"
      ],
      "id": "4ba4d3c7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Assign CAP workload\n",
        "\n",
        "capstones_per_lecture = model_sample['capstones_per_lecture']\n",
        "students_per_capstone = model_sample['students_per_capstone']\n",
        "\n",
        "senior_design_courses = ['CLSC403','EGRB401','EGRB402','CMSC441','CMSC442','CMSC451','CMSC452','EGMN402','EGMN403','ENGR402','ENGR403','EGRE404','EGRE405']\n",
        "for course in senior_design_courses:\n",
        "    # Set section type\n",
        "    stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['TYPE']=='LAB'),'wrkld_sample_type'] = 'CAP'\n",
        "    \n",
        "    # Estimate number of capstone sections using load of \"students_per_capstone\". Round up or down.\n",
        "    # This code was added after the initial code build, so we're storing the capstone_cnt in one of the spares we created above.\n",
        "    stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['wrkld_sample_type']=='CAP'),'capstone_cnt'] = ( 1.0* stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['wrkld_sample_type']=='CAP'),'ACTUAL ENROLLMENT'].astype(float) / students_per_capstone)\n",
        "\n",
        "    # apply CEIL function\n",
        "    stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['wrkld_sample_type']=='CAP'),'capstone_cnt'] = stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['wrkld_sample_type']=='CAP'),'capstone_cnt'].apply( np.ceil )"
      ],
      "id": "d0b995f4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, apply any necessary fixes. "
      ],
      "id": "74e97514"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## apply any fixes to number of capstone sections. Use TERM,CRN as keys"
      ],
      "id": "d4d1c0e9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, actually compute the workload based on the capstone_cnt.\n"
      ],
      "id": "4f74b92f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for course in senior_design_courses:\n",
        "    # Using the capstone count above, calculate the capstone workload\n",
        "    stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['wrkld_sample_type']=='CAP'),'sum_term_crse_wrkld_sample'] = (\n",
        "     stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['wrkld_sample_type']=='CAP'),'sum_term_crse_crn'] / capstones_per_lecture * ( stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['wrkld_sample_type']=='CAP'),'capstone_cnt'] ) )\n",
        "\n",
        "    # Update note to show adjustments\n",
        "    stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['wrkld_sample_type']=='CAP'),'wrkld_sample_note'] = (f\"RULE: [wrkld]={(1.0/capstones_per_lecture):0.2f} for every {students_per_capstone} students in CAP (CAP=\" +\n",
        "     stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['wrkld_sample_type']=='CAP'),'capstone_cnt'].astype(str) + \")\")"
      ],
      "id": "9c6ae930",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Distinguish VIP workloads\n",
        "\n",
        "[Vertically Integrated Programs (VIP) ](https://vip.vcu.edu/) provide undergraduate students the opportunity to participate in course-based, multiyear, multidisciplinary, team-based projects under the guidance of faculty and graduate students. These projects are in the faculty areas of expertise, with the main criterion for participation being that of mutual interest.\n",
        "\n",
        "Managing a VIP requires effort on the part of the faculty, yet at a lower rate than a standard class.\n"
      ],
      "id": "8b4710f8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Assign VIP workload\n",
        "\n",
        "vips_per_lecture = model_sample['vips_per_lecture']\n",
        "\n",
        "stacked_df.loc[stacked_df['course_number'].isin(['497']),'wrkld_sample_type'] = \"VIP\"\n",
        "stacked_df.loc[stacked_df['wrkld_sample_type'].isin(['VIP']),'wrkld_sample_note'] = f\"RULE: [wrkld]={(1.0/vips_per_lecture):0.2f} for VIP\"\n",
        "stacked_df.loc[(stacked_df['wrkld_sample_type'].isin(['VIP']))&(stacked_df['instructor_cnt']>1.0),'wrkld_sample_note'] = f\"RULE: [wrkld]={(1.0/vips_per_lecture):0.2f} for VIP (co-teaching)\"\n",
        "stacked_df.loc[stacked_df['wrkld_sample_type'].isin(['VIP']),'sum_term_crse_wrkld_sample'] = stacked_df.loc[stacked_df['wrkld_sample_type'].isin(['VIP']),'sum_term_crse_wrkld_sample'] / vips_per_lecture"
      ],
      "id": "a0b241ec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Distinguish LAB workloads\n",
        "\n",
        "Laboratory sections (LAB) are an important part of an engineering and computer science curriculum.\n",
        "\n",
        "LAB sections require effort on the part of the faculty member, but at a reduced rate. \n",
        "\n",
        "Identifying lab sections is tricky.  The College often codes lab sections differently across departments.  Some are coded properly as LAB \n",
        "sections.  \n",
        "\n",
        "In other cases, LAB sections are coded as LEC because they share the same CRN as their owner lecture.  To capture these\n",
        "cases a special logic is introduced.  If a section is taught once per week (e.g., M or W or TH) and the CRN has more than one meeting period, then the section with one meeting period is designated a LAB section. \n",
        "\n",
        "In reviewing the data I found some really odd coding. To accomodate this, I added an override\n",
        "block to turn specific tuples into lab sections.\n"
      ],
      "id": "df23edbb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "#| echo: false\n",
        "\n",
        "def fix_stacked( id, note, key, data ):\n",
        "    filter = (\n",
        "        (stacked_df[\"TERM\"]==key[\"TERM\"])\n",
        "        &(stacked_df[\"CRN\"]==key[\"CRN\"])\n",
        "        &(stacked_df[\"time_code\"]==key[\"time_code\"])\n",
        "        &(stacked_df[\"instructor\"]==key[\"instructor\"])\n",
        "        )\n",
        "\n",
        "    for item in data.keys():\n",
        "        stacked_df.loc[filter,item]=data[item]\n",
        "    stacked_df.loc[filter,\"fixes\"] += f\";FIX{id:03}\"\n",
        "    stacked_df.loc[filter,\"fix_notes\"] += \";\" + note"
      ],
      "id": "2fd473ee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Assign LAB workload\n",
        "labs_per_lecture = model_sample['labs_per_lecture']\n",
        "\n",
        "# Assign LAB sections\n",
        "stacked_df.loc[(stacked_df['mtgs_per_crn']>1)&(stacked_df['wrkld_sample_type']=='LEC')&(stacked_df['mtgs_per_wk']==1),'wrkld_sample_type'] = 'LAB'\n",
        "\n",
        "# Apply overrides for LAB sections\n",
        "\n",
        "fix_stacked(100,\"2x lab mtg\",\n",
        " {'TERM':'202410','CRN':12151,'time_code':'.T.R...14511559','instructor':'Abdelwahed,Sherif'},\n",
        " {'wrkld_sample_type':'LAB'}\n",
        ")\n",
        "\n",
        "# Create a note for all LAB sections\n",
        "stacked_df.loc[stacked_df['wrkld_sample_type'].isin(['LAB']),'wrkld_sample_note'] = f\"RULE: [wrkld]={(1.0/labs_per_lecture):0.2f} for LAB\"\n",
        "\n",
        "# Assign workload\n",
        "stacked_df.loc[stacked_df['wrkld_sample_type'].isin(['LAB']),'sum_term_crse_wrkld_sample'] = stacked_df.loc[stacked_df['wrkld_sample_type'].isin(['LAB']),'sum_term_crse_wrkld_sample'] / labs_per_lecture\n",
        "\n",
        "# Create a special note for LAB sections that used the special logic to be identified.\n",
        "stacked_df.loc[(stacked_df['mtgs_per_crn']>1)&(stacked_df['wrkld_sample_type']=='LAB')&(stacked_df['mtgs_per_wk']==1),'wrkld_sample_note'] = stacked_df.loc[(stacked_df['mtgs_per_crn']>1)&(stacked_df['wrkld_sample_type']=='LAB')&(stacked_df['mtgs_per_wk']==1),'wrkld_sample_note'] + \" (LAB: 1 mtg per wk rule)\""
      ],
      "id": "158a4330",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Distinguish RES, IND and FLD\n",
        "\n",
        "RES, IND and FLD sections are variable unit placeholders in banner that contribute to the full-time status calculation of a student, but\n",
        "don't necessarily reflect effort of the faculty mentor.\n",
        "\n",
        "Research active faculty are most associated with RES, IND and FLD.  To capture the workload we have two options:\n",
        "\n",
        "1. We can associate these units with a non-zero workload value, or\n",
        "1. We can reduce the workloads of research active faculty.\n",
        "\n",
        "To do both would double-count the effort of RES, IND and FLD sections.\n",
        "\n",
        "For purposes of this workload model, we'll zero these out and let research active faculty have reduced workloads.\n"
      ],
      "id": "3e339bb3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Exclude teaching credit for research (RES), independent study (IND), and intern/coop (FLD).\n",
        "# Credit is given for these activities in reduced teaching (research active) or summer pay.\n",
        "stacked_df.loc[stacked_df['wrkld_sample_type'].isin(['RES','IND','FLD']),'wrkld_sample_note'] = \"RULE: [wrkld]=0.00 for INS, RES and FLD\"\n",
        "stacked_df.loc[stacked_df['wrkld_sample_type'].isin(['RES','IND','FLD']),'sum_term_crse_wrkld_sample'] = model_sample['res_ind_fld_per_lecture']"
      ],
      "id": "66c3c551",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Distinguish SEM workloads\n",
        "\n",
        "The seminar class is an important part of our curriculum and requires effort of those organizing the course.  \n",
        "\n",
        "In this workload model, the seminar counts as a full workload course.\n"
      ],
      "id": "ee8e311b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Assign SEM workload\n",
        "# Ensure that SEM get full credit because we want to reward the faculty member for doing it!\n",
        "\n",
        "seminars_per_lecture = model_sample['seminars_per_lecture']\n",
        "\n",
        "stacked_df.loc[stacked_df['wrkld_sample_type'].isin(['SEM']),'wrkld_sample_note'] = f\"RULE: [wrkld] / {seminars_per_lecture} for SEM\"\n",
        "stacked_df.loc[(stacked_df['wrkld_sample_type'].isin(['SEM']))&(stacked_df['instructor_cnt']>1.0),'wrkld_sample_note'] = f\"RULE: [wrkld] / {seminars_per_lecture} for SEM (co-teaching)\"\n",
        "stacked_df.loc[stacked_df['wrkld_sample_type'].isin(['SEM']),'sum_term_crse_wrkld_sample'] = stacked_df.loc[stacked_df['wrkld_sample_type'].isin(['SEM']),'sum_term_crse_wrkld_sample'] / seminars_per_lecture"
      ],
      "id": "31f4eb15",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adjust for large lectures\n",
        "\n",
        "Larger lectures require more effort.  The code blocks below adjust the base workload for large classes.\n"
      ],
      "id": "9eb0ec53"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#  Process large classes using thresholds and weights in model_sample parameters.\n",
        "\n",
        "for threshhold,weight in model_sample['large_classes']:\n",
        "    stacked_df.loc[(stacked_df['ACTUAL ENROLLMENT']>=threshhold)&(stacked_df['wrkld_sample_type']=='LEC'),\"sum_term_crse_wrkld_sample\"] = weight / stacked_df[\"instructor_cnt\"]\n",
        "    stacked_df.loc[(stacked_df['ACTUAL ENROLLMENT']>=threshhold)&(stacked_df['wrkld_sample_type']=='LEC'),\"wrkld_sample_note\"] = f\"BASE: [wrkld] = {weight} per CRN ENRL>={threshhold}\"\n",
        "    stacked_df.loc[(stacked_df['ACTUAL ENROLLMENT']>=threshhold)&(stacked_df['wrkld_sample_type']=='LEC')&(stacked_df['instructor_cnt']>1.0),'wrkld_sample_note'] = f\"BASE: [wrkld]={weight/2.0} per CRN ENRL>={threshhold} (co-teaching)\""
      ],
      "id": "0107ec01",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Store LEC-only workload in separate column.\n"
      ],
      "id": "2a254612"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "stacked_df['sum_term_crse_wrkld_sample_lec'] = 0.0\n",
        "stacked_df.loc[(stacked_df['wrkld_sample_type']=='LEC'),'sum_term_crse_wrkld_sample_lec'] = stacked_df.loc[(stacked_df['wrkld_sample_type']=='LEC'),'sum_term_crse_wrkld_sample']"
      ],
      "id": "136c135b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Store list of LECT-only courses \n"
      ],
      "id": "d938d029"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def list_courses( x ):\n",
        "    l = x.unique().tolist()\n",
        "    l = list(filter(lambda item: item != \"\", l))\n",
        "    return \",\".join(l)\n",
        "\n",
        "temp  = stacked_df.copy()\n",
        "temp[\"lec-only-course\"] = \"\"\n",
        "temp.loc[temp['wrkld_sample_type']=='LEC',\"lec-only-course\"] = temp.loc[temp['wrkld_sample_type']=='LEC',\"COURSE\"]\n",
        "stacked_df['lec_only_course_list'] = temp.groupby(['TERM','instructor'])['lec-only-course'].transform( list_courses )\n",
        "\n",
        "stacked_df[(stacked_df['instructor']=='Leonard,John')&(stacked_df['TERM'].isin(['202410','202320']))][['TERM','COURSE','lec_only_course_list']]"
      ],
      "id": "f304d252",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary\n",
        "\n",
        "At this point the model building is done and the workload assignments are stored in the appropriate columns.\n",
        "\n",
        "\n",
        "## Examples, checks and verifications\n",
        "\n",
        "The following code blocks are added as unique situations are discovered.  The code below\n",
        "shows how these situations are handled and demonstrates how they were corrected.\n",
        "\n",
        "As odd situations are revealed, add a code block here to clearly show the inconsistency.  Then, change\n",
        "the workload code above until the situation clears up AND you don't screw up any of the other situations.\n",
        "\n",
        "### Example: LECT / LAB\n",
        "\n",
        "In this example, a lecture/lab course was coded as 3 separate CRN.  Each CRN has a main lecture and a single-meeting-period lab.\n",
        "\n",
        "All three lectures share the same meeting time and are combined into a single workload LECT.  Each lab section is assigned 1/3 workload.\n",
        "\n",
        "However, two of the lab sections share a common meeting time, so they are combined into a single 1/3 workload section.\n"
      ],
      "id": "46640e9c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def show_block( df,keys,cols):\n",
        "    tdf = df\n",
        "    for key in keys.keys():\n",
        "        tdf = tdf[tdf[key]==keys[key]]\n",
        "    return tdf[cols]\n",
        "\n",
        "show_block(stacked_df,\n",
        "    {'TERM':'202410','COURSE':'EGMN416'},\n",
        "    ['COURSE','CRN','TYPE','TITLE','instructor','time_code',\n",
        "    'sum_term_crse_crn',\n",
        "    'sum_term_crse_crn_mtg_students',\n",
        "    'sum_term_crse_crn_hours',\n",
        "    'sum_term_crse_wrkld_sample','wrkld_sample_type','wrkld_sample_note']\n",
        ")"
      ],
      "id": "036c5cda",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* *sum_term_crse_crn* represents the number of unique CRNs.  This value is split across multiple meeting times per CRN.\n",
        "\n",
        "* *sum_term_crse_crn_mtg_students* represents the number of students in each crn-meeting time. This value is useful to determine how many students are in any given meeting time.\n",
        "\n",
        "* *sum_term_crse_crn_hours* represents the number of credit hours associated with a CRN.  This value is split across multiple meeting times.\n",
        "\n",
        "### Example: LECT sharing a common time\n",
        "\n",
        "In this example, two CRN are sharing a common teaching time and their workloads are split across the two CRN.\n"
      ],
      "id": "dc796375"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "show_block(stacked_df,\n",
        "    {'TERM':'202320','instructor':\"Heise,Rebecca\"},\n",
        "    ['COURSE','CRN','TYPE','TITLE','instructor','time_code','sum_term_crse_wrkld_sample','wrkld_sample_type','wrkld_sample_note']\n",
        ")"
      ],
      "id": "63236449",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example: Miscode?\n",
        "\n",
        "This record shows two CRN overlapping in teaching time, but not exactly matching teaching times.  Is this for real? Is this a miscode?  My initial guess is that this is a miscode and the times should be corrected.  This can be accomplished with a FIX record above."
      ],
      "id": "cbb8ef1c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "show_block(stacked_df,\n",
        "    {'TERM':'202310','instructor':\"Ferri,James\"},\n",
        "    ['COURSE','CRN','TYPE','TITLE','instructor','time_code','MODALITY CODE','sum_term_crse_wrkld_sample','wrkld_sample_type','wrkld_sample_note']\n",
        ")"
      ],
      "id": "555064f7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example: Singleton ROND\n",
        "\n",
        "This shows a singleton ROND sections.  Synchronous on-line sections (ROND) should always be taught with an in-person section. In this\n",
        "case I can only imagine that no students enrolled in the RINP/face-to-face section and it was dropped during earlier data cleaning.\n"
      ],
      "id": "1d48e4c8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "show_block(stacked_df,\n",
        "    {'TERM':'202320','instructor':\"Manic,Milos\"},\n",
        "    ['COURSE','CRN','TYPE','TITLE','instructor','time_code','MODALITY CODE','sum_term_crse_wrkld_sample','wrkld_sample_type','wrkld_sample_note']\n",
        ")"
      ],
      "id": "1738c486",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example: Doubleton ROND+RINP\n",
        "\n",
        "This second example shows a doubleton ROND+RINP section.\n"
      ],
      "id": "62af53e8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "show_block(stacked_df,\n",
        "    {'TERM':'202410','instructor':\"Ghosh,Preetam\"},\n",
        "    ['COURSE','CRN','TYPE','TITLE','instructor','time_code','MODALITY CODE','sum_term_crse_wrkld_sample','wrkld_sample_type','wrkld_sample_note']\n",
        ")"
      ],
      "id": "00a1a5b6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example: odd counting \n",
        "\n",
        "Verifying actual enrollment vs sum_term_crse_wrkld_sample\n"
      ],
      "id": "5858797b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "show_block(stacked_df,\n",
        "    {'TERM':'202410','instructor':\"Duke,Debra\",'COURSE':'CMSC256'},\n",
        "    ['COURSE','CRN','TYPE','TITLE','instructor','time_code','MODALITY CODE','ACTUAL ENROLLMENT','MAX CREDITS','time_code','sum_term_crse_crn_mtg_students','sum_term_crse_crn_hours',\n",
        "    'sum_term_crse_wrkld_sample','wrkld_sample_type','wrkld_sample_note']\n",
        ")"
      ],
      "id": "88a23b14",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example: odd counting \n",
        "\n",
        "Verifying actual enrollment vs sum_term_crse_wrkld_sample\n"
      ],
      "id": "c5a8d435"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "show_block(stacked_df,\n",
        "    {'TERM':'202410','instructor':\"Duke,Debra\",'COURSE':'CMSC256'},\n",
        "    ['COURSE','CRN','TYPE','TITLE','instructor','time_code','MODALITY CODE','ACTUAL ENROLLMENT','MAX CREDITS','time_code','sum_term_crse_crn_mtg_students','sum_term_crse_crn_hours',\n",
        "    'sum_term_crse_wrkld_sample','wrkld_sample_type','wrkld_sample_note']\n",
        ")"
      ],
      "id": "fbe4c89f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Store the dataframe\n",
        "\n",
        "We're storing both the stacked and unstacked data.  Note that the\n",
        "aggregate measures are stored with the stacked data only.\n",
        "\n",
        "### Store to a local CSV file\n"
      ],
      "id": "289ea26b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Store as CSV files\n",
        "sections_df.to_csv('sections_df.csv', index=False)\n",
        "stacked_df.to_csv('stacked_df.csv', index=False)"
      ],
      "id": "3618dff9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Store the data in google sheets\n"
      ],
      "id": "e13b95ef"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Open the worksheet \n",
        "spreadsheet_key = \"1ZK7k8M85CXLof6FdeJYJuGFbfjsOXrCv5mc7OgUInWw\"\n",
        "worksheet_name = \"Source data\"\n",
        "\n",
        "data_to_write = stacked_df.to_records(index=False)\n",
        "try:\n",
        "    sheet = client.open_by_key(spreadsheet_key).worksheet(worksheet_name)\n",
        "except:\n",
        "    sheet = client.open_by_key(spreadsheet_key).add_worksheet( \n",
        "        title = worksheet_name,nrows=100,ncols=10\n",
        "    )\n",
        "try:\n",
        "    sheet.clear()\n",
        "    set_with_dataframe(worksheet=sheet, dataframe=stacked_df, include_index=False,include_column_header=True, resize=True)\n",
        "except:\n",
        "    print(f\"Data can't be written\")\n"
      ],
      "id": "9dc7ce3d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Freshen persistent instructor data\n",
        "\n",
        "This block identifies any instructors not found in the persistent instructor data\n",
        "and adds them to the list with default values.\n",
        "\n",
        "**This code is not working yet.** It should be fixed when a new semester is added and new instructors and courses\n",
        "are discovered in the imported worksheets.\n"
      ],
      "id": "4df7059f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "#worksheet_name = \"Instructor data\"\n",
        "#summary_df = stacked_df.groupby('instructor')[['COLLEGE','DEPT']].apply(lambda x: x.mode().iloc[0]).#reset_index()\n",
        "#summary_df = summary_df.sort_values(by=['COLLEGE','DEPT','instructor'])\n",
        "#data_to_write = summary_df.to_records(index=False)\n",
        "#try:\n",
        "#    sheet = client.open_by_key(spreadsheet_key).worksheet(worksheet_name)\n",
        "#except:\n",
        "#    nrows,ncols = summary_df.shape\n",
        "#    sheet = client.open_by_key(spreadsheet_key).add_worksheet( \n",
        "#        title = worksheet_name,rows=nrows+1,cols=ncols+1\n",
        "#    )\n",
        "#sheet.clear()\n",
        "#set_with_dataframe(worksheet=sheet, dataframe=summary_df, include_index=False,include_column_header=True, resize=True)\n",
        "\n",
        "# Find names in df2 that are not in df1\n",
        "##names_to_add = df2[~df2['name'].isin(df1['name'])]\n",
        "\n",
        "# Add the rows with missing names from df2 to df1\n",
        "## df1 = pd.concat([df1, names_to_add], ignore_index=True)"
      ],
      "id": "f324d128",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "That's all folks!  Additional models can be added and the google sheets can be reviewed.\n",
        "\n",
        "Now the real analysis can begin:\n",
        "\n",
        "* [here is a link to a google sheet](https://docs.google.com/spreadsheets/d/1ZK7k8M85CXLof6FdeJYJuGFbfjsOXrCv5mc7OgUInWw/edit#gid=1484314377) that shows tables created from the dataframe.\n",
        "* [here is a HTML report](30_explore.qmd) that is still evolving.\n",
        "* [here is the CSV for the cleaned dataframe](stacked_df.csv).  This dataframe contains one tuple per (TERM,CRN,INSTRUCTOR,MEETING_CODE)."
      ],
      "id": "989a76d6"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}