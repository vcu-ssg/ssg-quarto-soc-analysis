[
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Workloads",
    "section": "",
    "text": "import pandas as pd\nimport panel as pn\nfrom panel.interact import interact\nfrom panel.widgets import DataFrame\n\npn.extension('tabulator')\n\n# Sample DataFrame\ndata = {'Name': ['Alice', 'Bob', 'Charlie'],\n        'Value1': [10, 20, 30],\n        'Value2': [3, 2, 5],\n        }\ndf = pd.DataFrame(data)\n\ndef generate_bar_html(row, dataframe):\n    value1 = row['Value1']\n    value2 = row['Value2']\n    max_val = dataframe[['Value1', 'Value2']].sum(axis=1).max()\n    width1 = 100 * (value1 / max_val)\n    width2 = 100 * (value2 / max_val)\n    \n    html_content = f\"\"\"\n    &lt;div style=\"width: 100%; display: flex; height: 100%; align-items: center;\"&gt;\n        &lt;div style=\"width: {width1}%; background-color: blue; height: 100%;\"&gt;&lt;/div&gt;\n        &lt;div style=\"width: {width2}%; background-color: red; height: 100%;\"&gt;&lt;/div&gt;\n    &lt;/div&gt;\n    \"\"\"\n    return html_content\n\ndf['Bar'] = df.apply(generate_bar_html, dataframe=df, axis=1)\n\n# Setting up the Tabulator widget\ntabulator = pn.widgets.Tabulator(df, width=400, height=200,\n                                  formatters={\n                                    'Value1' : {'type': 'progress','max' : '40'},\n                                    'Value2' : {'type': 'star','stars' : '5'},\n                                    'Bar': {'type':'html'}\n                                   })\n\n# Show the panel\ntabulator.servable()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analysis of Teaching",
    "section": "",
    "text": "This web report presents an application of a sample model of faculty workload over the past two semesters (Spring 2023 and Fall 2023).\nThis is intended to be a living analysis. As additions and corrections are found please let me know and we can implement the necessary changes and re-render the report.\nThis report was developed using Quarto, an open-source scientific and technical publishing designed with reproducibility in mind. Analyses were performed using python. The source code for the pages on this site are available in a github repository."
  },
  {
    "objectID": "index.html#report-organization",
    "href": "index.html#report-organization",
    "title": "Analysis of Teaching",
    "section": "Report organization",
    "text": "Report organization\nThe site is organized as follow:\n\nDownload - this section describes the source of data (VCU reports) and shows the files and semesters downloaded. This section is provided so that others can obtain the same data used for this report.\nClean - this section documents the cleaning strategies applied to the data obtained above. This section refactors and reshapes the data, adds new columns and corrects known errors. The data are stored in this repo, and are also uploaded to this google sheet.\nExplore - this section offers several sample analysis using the cleaned data. This report is generated using python and matplotlib. The examples are offered as demonstrations of the possible, not as part of a real analysis of workload."
  },
  {
    "objectID": "index.html#rolling-your-own-model",
    "href": "index.html#rolling-your-own-model",
    "title": "Analysis of Teaching",
    "section": "Rolling your own model",
    "text": "Rolling your own model\nThe resulting dataframe is available here for download as CSV.\nThe result dataframe is also uploaded to a google workbook and a sample analysis is conducted."
  },
  {
    "objectID": "index.html#persistent-data",
    "href": "index.html#persistent-data",
    "title": "Analysis of Teaching",
    "section": "Persistent data",
    "text": "Persistent data\nThe banner report used to create this report does not contain all the necessary data to complete the analysis (e.g., instructor department).\nPersistent data are stored in a google sheet.\nInstructor data - these data provide instructor departments and instructor roles, and an instructor workload designation. This table is necessary for the analysis.\nInstructor notes - these data offer additional details about instructors. It is expected that these data might be incorporated into a subsequent workload report. This table is optional to this analysis.\nCourse notes - these data offer additional details about the courses. This table is optional to this analysis."
  },
  {
    "objectID": "40_workload.html",
    "href": "40_workload.html",
    "title": "Workloads",
    "section": "",
    "text": "These are experimental presentations of the data."
  },
  {
    "objectID": "40_workload.html#explore-tabular-data",
    "href": "40_workload.html#explore-tabular-data",
    "title": "Workloads",
    "section": "Explore tabular data",
    "text": "Explore tabular data\n\ncols = ['instructor','ins_dept','TERM','COURSE','TITLE','wrkld_sample_type','sum_term_crse_wrkld_sample','wrkld_sample_note']\nterms = [202410,202320]\n\n# Strip whitespace from column names\nstacked_df.columns = stacked_df.columns.str.strip()\n\ndf = stacked_df[stacked_df[\"TERM\"].isin(terms)][cols]\n\nbokeh_formatters = {\n    'TERM': NumberFormatter(format='000000')\n}\n\ntable = pn.widgets.Tabulator(df,\n    show_index=False,\n    formatters=bokeh_formatters\n)\n\ntable"
  },
  {
    "objectID": "31_explore.html",
    "href": "31_explore.html",
    "title": "Instructor workloads - Fall 2023/Spring 2024",
    "section": "",
    "text": "The table below shows application of the workload model to the current academic year. Relative workloads are also visualized. Four major metrics are highlighted:\n\nTotal workload (Wrkld), the cumulative workload for lectures, labs, seminar, capstones and VIP, with one workload unit equivelent to one standard lecture course per semester.\nLecture workload (W.Lec), the cumulative workload associated with lecture classes. This most closely corresponds to the traditional workload conversation (e.g., 1+1 would show as 2, 2+1 or 1+2 would show as 3, etc.)\nLecture hours (Hr.Lec) the cumulative credit hours (number of students enrolled * course credit) for just lecture sections,\nTotal Hours (Hours), the cumulative credit hours for all sections. This value drives the VCU budget model, as a portion of each unit’s budget is estimated on a per-credit hour basis for the academic year.\n\nThe visualization on the right shows two horizontal, stacked bars, centered around an axis, showing workload extending to the left and credit hours extending to the right. Bars represent lecture-only and non-lecture units so that the total bar length represents the total, either workload units or credit hours.\nColumns can be sorted using the triangle icon. Holding  permits sorting over multiple columns.\nThe median (50th percentile across instructors) for total workload and total hours is also shown.\nIndividual faculty rows can be expanded to explore the details of each computation. The detail table shows each CRN, workload assignments, and the rule applied to derive the value.\n\n\nCMSCMNEECEBMECLSEAllModel\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\nBelow is the workload model used for this analysis. These rules are applied to each CRN and faculty member for the respective terms.\n\nmodel_sample = {\n    'base_lecture_value':1.0,\n    'labs_per_lecture':3.0,\n    'vips_per_lecture':3.0,\n    'capstones_per_lecture': 3.0,\n    'students_per_capstone': 4.0,\n    'seminars_per_lecture': 1.0,\n    'res_ind_fld_per_lecture': 0.0,\n    'large_classes': [ [80,1.5],[160,2.0],[240,2.5] ]\n}\n\n\nEach section (or CRN/course reference number) is assigned base of 1.0 workload units.\nLab sections including actual course labs, capstone/senior design, and VIP receive 1/3 credit. This is consistent with the model that 3 lab hours is equivalent to 1 teaching hour. (e.g., 3-3-4 courses.) Many departments in EGR code lab sections as lecture sections, making it difficult to discern. We can identify lab sections by class meetings - if a CRN has multiple class meetings, one meeting multiple times per week and another meeting only once per week, the lab is denoted as the once-per-week meeting. See this section for more details.\nSeminar sections get full section credit as a positive incentive. There is a limited number of SEM courses, they are important to the curriculum, and we want them covered.\nCapstone designs are scaled to give one LAB (0.33 per above) unit per groups of 4 students.\nResearch, indepedent study and coop/intern sections receive zero teaching credit in this workload model. Research active faculty receive reduced teaching loads, rather than credit for these units.\n\nSignificant effort was also invested in the corresponding google workbook."
  },
  {
    "objectID": "20_clean.html",
    "href": "20_clean.html",
    "title": "Cleaning the data",
    "section": "",
    "text": "This script describes the data and walks through a process of data cleaning.\nAt completion of this script all the individual semester data files will be combined into a single dataframe for analysis, and the dataframe will be refactored for cleaner analysis.\nTLDR: Here is a link to the cleaned dataframe. This dataframe contains one tuple per (TERM,CRN,INSTRUCTOR,MEETING_CODE).\nTLDR: Here is a link to the google sheet with the cleaned data loaded in the “source data” tab and other sheets referencing the source data."
  },
  {
    "objectID": "20_clean.html#data-sources",
    "href": "20_clean.html#data-sources",
    "title": "Cleaning the data",
    "section": "Data sources",
    "text": "Data sources\nThe files are named appropriately and stored in the data folder in this repository."
  },
  {
    "objectID": "20_clean.html#data-cleaning",
    "href": "20_clean.html#data-cleaning",
    "title": "Cleaning the data",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nThe following sections combine the individual sources of data and clean them up.\n\nCombining to single data frame\nThe following section combines each XLSX into a single data frame. The contents of the files are variable in length depending on the number of sections taught during any given semester.\nThe appropriate block starts one row after the row with the keyword TERM in the first column, denoting the header row. The appropriate block ends with the row prior to the row with the keyword N =.\nWe’re assuming that all xlsx workbooks share the same columns and names.\n\n# Initialize an empty list to store trimmed DataFrames\ntrimmed_dfs = []\n\n# Iterate through the list of XLSX file names\nfor file_name in xlsx_df['file_name']:\n    # Load the XLSX file into a DataFrame\n    full_path = os.path.join(directory_path, file_name)\n    df = pd.read_excel(full_path)\n    \n    # Find the row index where \"TERM\" is in the first column\n    term_index = df.index[df.iloc[:, 0] == \"TERM\"].tolist()[0]\n    \n    # Find the row index where \"N=\" is in the first column\n    n_index = df.index[df.iloc[:, 0].fillna('x').astype(str).str.startswith(\"N =\")].tolist()[0]\n\n    # Clip the desired block and add column names\n    trimmed_df = df.loc[term_index + 1 : n_index - 1]\n    trimmed_df.columns = df.iloc[term_index].values\n\n    # Append the trimmed DataFrame to the list\n    trimmed_dfs.append(trimmed_df)\n\n# Combine the individual dataframes into one big one.\nsections_df = pd.concat(trimmed_dfs, ignore_index=True)\n\n\n\nMerge in the term and period data from the xlsx_df dataframe\nThe following code merges in the term and period data with the section data. First ensure that the key columns are strings, then merge away.\n\nsections_df['SECT'] = sections_df['SECT'].astype(str)\nsections_df['TERM'] = sections_df['TERM'].astype(str)\nxlsx_df['term_code'] = xlsx_df['term_code'].astype(str)\nsections_df = pd.merge(sections_df,xlsx_df,left_on='TERM', right_on='term_code', how='left')\n\n\n\nRemove duplicate instructor1 and instructor2\n\ndef replace_matches(row):\n    if row['PRIMARY INSTRUCTOR FIRST NAME'] == row['SECONDARY INSTRUCTOR FIRST NAME'] and row['PRIMARY INSTRUCTOR LAST NAME'] == row['SECONDARY INSTRUCTOR LAST NAME']:\n        row['SECONDARY INSTRUCTOR FIRST NAME'], row['SECONDARY INSTRUCTOR LAST NAME'] = '', ''\n    return row\nsections_df = sections_df.apply( replace_matches,axis=1)\n\n\n\nFix known errors\nThe data in Banner doesn’t always reflect reality. This step corrects known errors in the data.\nNote that the section data are stored one row per term-crn-meeting period.\nThe purpose of this section is to demonstrate an auditable process for documenting changes to the source data.\nThere is nothing magic about the changes below. As I shared the data with others, they found that the banner data did not reflect reality. For this workload analysis we want the data to reflect reality, so we fix it.\nAdditional fixes are expected to be added as new eyes look at their data.\n\n# Spring 2023: CMSC475 John Leonard taught for David Shepherd\nfix_sections(1,'Swap Leonard for Shepherd',{'TERM':'202320','CRN':'43471'},{'PRIMARY INSTRUCTOR FIRST NAME':'John','PRIMARY INSTRUCTOR LAST NAME':'Leonard'})\n\n# Fall 2024: CMSC391 is cross listed with COAR463.\n# Total enrollment 34 across two instructors (Bennett and Leonard)\n# Currently Banner shows only 20 in the JL section and doesn't mention the COAR section.\nfix_sections(2,'Fix incorrect cross listing',{'TERM':'202410','CRN':'46263'},{'ACTUAL ENROLLMENT':34})\n\nfix_sections(3,\"Capstone common course is LEC not SEM\",{'TERM':'202320','CRN':'45290'},{'TYPE':'LEC'})\n\nfix_names(4,\"Rename instructor\",\n{'first_name':'Sheng-Chieh','last_name':'Chen'},{'first_name':'Shawn','last_name':'Chen'})\n\nfix_names(5,\"Rename instructor\",\n{'first_name':'Bernard','last_name':'Gupton'},{'first_name':'Frank','last_name':'Gupton'})\n\nfix_names(6,\"Rename instructor\",\n{'first_name':'Anathea','last_name':'Pepperl'},{'first_name':'Thea','last_name':'Pepperl'})\n\nfix_names(7,\"Rename instructor\",\n{'first_name':'Robert','last_name':'Dahlberg'},{'first_name':'Bob','last_name':'Dahlberg'})\n\nfix_names(8,\"Rename instructor\",\n{'first_name':'Philip','last_name':'Longest'},{'first_name':'Worth','last_name':'Longest'})\n\nfix_names(9,\"Rename instructor\",\n{'first_name':'Jonathan','last_name':'Buffkin'},{'first_name':'Seth','last_name':'Buffkin'})\n\nfix_names(10,\"Rename instructor\",\n{'first_name':'Jonathan','last_name':'Buffkin'},{'first_name':'Seth','last_name':'Buffkin'})\n\n\n\nReshape the data\nThe current dataframe sections_df contains one record per term-crn-meeting period tuple. Within each tuple there can be up to 2 instructors. We need to reshape the data with the instructors in a single column.\nWhile we’re here we can combine instructor first and last name, and drop verbose columns.\n\ncols = sections_df.columns\nvalues_to_remove = ['PRIMARY INSTRUCTOR FIRST NAME','PRIMARY INSTRUCTOR LAST NAME','SECONDARY INSTRUCTOR FIRST NAME','SECONDARY INSTRUCTOR LAST NAME']\ncols = [x for x in cols if x not in values_to_remove]\n\nsections_df['ins1_last'] = sections_df['PRIMARY INSTRUCTOR LAST NAME']\nsections_df['ins1_first'] = sections_df['PRIMARY INSTRUCTOR FIRST NAME']\nsections_df['ins2_last'] = sections_df['SECONDARY INSTRUCTOR LAST NAME']\nsections_df['ins2_first'] = sections_df['SECONDARY INSTRUCTOR FIRST NAME']\nsections_df['instructor_1'] = sections_df['ins1_last']+sections_df['ins1_first'].apply(lambda x: ',' if x != \"\" else \"\")+sections_df['ins1_first']\nsections_df['instructor_2'] = sections_df['ins2_last']+sections_df['ins2_first'].apply(lambda x: ',' if x != \"\" else \"\")+sections_df['ins2_first']\nsections_df['instructor_1'].astype(str).fillna('',inplace=True)\nsections_df['instructor_2'].astype(str).fillna('',inplace=True)\n\nstacked_df = pd.melt(sections_df,\n    id_vars=cols,\n    value_vars=['instructor_1','instructor_2'],\n    var_name='instructor source',\n    value_name='instructor'\n)\n\n\n\nClean up rows\nThe process above introduces records with missing instructor_2. This code removes records missing instructor_2.\n\n# remove rows with empty instructor 2.  Keep rows with empty instructor 1.\nstacked_df = stacked_df[ ~ ((stacked_df['instructor source']=='instructor_2') & (stacked_df['instructor'].isna() | (stacked_df['instructor']==''))) ]\n\nIn some summer courses an instructor was not listed in the data. An instructor name is generated using the course and semester. This can be cleaned later.\n\n# replace any missing instructors with note\nstacked_df.loc[stacked_df[\"instructor\"].isin(['']),\"instructor\"] = stacked_df[stacked_df[\"instructor\"].isin([''])]['COURSE']+' '+stacked_df[stacked_df[\"instructor\"].isin([''])]['TERM']+' '+stacked_df[stacked_df[\"instructor\"].isin([''])]['CRN']\n\nSome sections, for example RES sections or cancelled sections have zero enrollments. These are removed, keeping only sections with positive enrollments.\n\n# drop rows with zero enrollments\nstacked_df = stacked_df[stacked_df['ACTUAL ENROLLMENT']&gt;0]\n\nWhile not necessary, the resulting dataframe can be sorted so that it looks pretty when saved to a CSV.\n\n# Sort the data frame so it looks pretty in the output file.\nstacked_df = stacked_df.sort_values(['TERM','DEPT','COURSE','SECT','instructor source','instructor'])\n\n\n\nAdd additional data columns\nWe may need the subject and the course number in the workload model analysis.\n\nstacked_df[\"course_subject\"] = stacked_df[\"COURSE\"].str[:4]\nstacked_df[\"course_number\"] = stacked_df[\"COURSE\"].str[4:]\n\nFor each section, add a new field with the count of instructors sharing this section. This helps with workload and other computations later.\n\n# Number of instructors sharing a common CRN.\nstacked_df[\"instructor_cnt\"] = stacked_df.groupby(['TERM','COURSE','CRN'])['CRN'].transform('count') / stacked_df.groupby(['TERM','COURSE','CRN','instructor'])['instructor'].transform('count') \n\nstacked_df[\"capstone_cnt\"] = 0.0  # used downstream to provide an actual capstone count rather than an estimated count of capstone sections.\n\nIt’s getting old adding new columns, then having to rework the formuluas in the rather brittle google sheet. I’m adding a few spare columns here to be used as necessary. This is the best place to add the new columns, just prior to the calculation of the aggregate measures and workload attributes.\n\nstacked_df[\"lec_only_course_list\"] = \"\"\nstacked_df[\"sum_term_crse_crn_hours_lec\"] = 0  # used 4/27/2024. Search for \"Store LEC-only workload\", below, after workload calcs.\nstacked_df[\"spare_col_3\"] = 0\nstacked_df[\"spare_col_4\"] = 0\nstacked_df[\"spare_col_5\"] = 0\nstacked_df[\"spare_col_6\"] = 0\n\n\n\nMerge persistent instructor data\nThe Banner report that we’re using for this analysis does not include all the necessary data for a proper analysis. The report infers the offering department of the course (e.g., ENGR497 or CMSC475), but not the home department of the instructor. For example, capstone courses are coded ad ENGR497, but the record won’t include the home department of the instructor, making it difficult to roll up all the courses by home department of the instructor.\nWe store persistent instructor and course data in a separate google sheet. As these persistent data are changed or corrected, this analysis should be regenerated to use these amended data.\nThe code below merges the persistent instructor data from the google sheet into the working dataframe.\n\n# define scope\nscope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n\n# create credentials object\ncredential_file = os.path.join(os.path.expanduser(\"~\"), \".gsecrets\", \"gsheets-credentials.json\")\nif not os.path.isfile( credential_file ):\n  print(\"Missing credential file:\",credential_file)\n  sys.exit()\n\n# authorize the client\ncreds = ServiceAccountCredentials.from_json_keyfile_name(credential_file, scope)\nclient = gspread.authorize(creds)\n\nspreadsheet_key = \"1ZK7k8M85CXLof6FdeJYJuGFbfjsOXrCv5mc7OgUInWw\"\nworksheet_name = \"Instructor data\"\n\nsheet = client.open_by_key(spreadsheet_key).worksheet(worksheet_name)\ninstructor_df = get_as_dataframe(worksheet=sheet, evaluate_formulas=True)\n\n\nstacked_df = pd.merge( stacked_df,instructor_df,left_on='instructor',right_on='instructor',how='left')\n\n\nmissing_records = stacked_df[stacked_df['ins_dept'].isna()]\nmissing_records[['instructor','COURSE','TERM']].drop_duplicates(subset='instructor')\n\n\n\n\n\n\n\n\ninstructor\nCOURSE\nTERM\n\n\n\n\n2344\nNaN\nEGRB697\n202230\n\n\n\n\n\n\n\n\nworksheet_name = \"Instructor notes\"\nsheet = client.open_by_key(spreadsheet_key).worksheet(worksheet_name)\ninstructor_notes_df = get_as_dataframe(worksheet=sheet, evaluate_formulas=True )\ninstructor_notes_df = instructor_notes_df.dropna(subset=['instructor'])\n\n\nstacked_df = pd.merge( stacked_df,instructor_notes_df,left_on='instructor',right_on='instructor',how='left')\n\n\n\nMerge persistent course data\nPersistent course data is also stored in the google sheet and merged with the working dataframe.\n\n# spreadsheet_key = \"1ZK7k8M85CXLof6FdeJYJuGFbfjsOXrCv5mc7OgUInWw\" from above!\nworksheet_name = \"Course notes\"\nsheet = client.open_by_key(spreadsheet_key).worksheet(worksheet_name)\ncourse_notes_df = get_as_dataframe(worksheet=sheet, evaluate_formulas=True )\ncourse_notes_df = course_notes_df.dropna(subset=['crse'])\n\n\nstacked_df = pd.merge( stacked_df,course_notes_df,left_on='COURSE',right_on='crse',how='left')\n\n\nmissing_records = stacked_df[stacked_df['crse_url'].isna()].drop_duplicates(subset='COURSE')\nmissing_records[['COURSE','TERM']]\n\n\n\n\n\n\n\n\nCOURSE\nTERM\n\n\n\n\n\n\n\n\n\n\n\nIdentify shared rooms\nSome CRN share the same classroom and instructor. Examples might include an UG and GR section sharing the same lecture, or multiple LEC/LAB combos sharing the same LEC with different LAB rooms and time.\nTo properly identify shared lectures we need to identify unique combinations of days of week and rooms and assign store these values for later aggregation.\n\ntime_cols = ['MON-IND','TUE-IND','WED-IND','THU-IND','FRI-IND','SAT-IND','SUN-IND','BEGIN TIME','END TIME']\nroom_cols = ['BUILDING','ROOM']\n\nstacked_df[\"time_code\"] = \"\"\nfor col in time_cols:\n    stacked_df[col] = stacked_df[col].fillna('.')\n    stacked_df[\"time_code\"] = stacked_df[\"time_code\"] + stacked_df[col].astype(str)\nstacked_df['time_id'] = pd.factorize(stacked_df['time_code'])[0]\n\nstacked_df[\"room_code\"] = \"\"\nfor col in room_cols:\n    stacked_df[col] = stacked_df[col].fillna('.')\n    stacked_df[\"room_code\"] = stacked_df[\"room_code\"] + stacked_df[col].astype(str)\nstacked_df['room_id'] = pd.factorize(stacked_df['room_code'])[0]\n\nstacked_df[\"meeting_code\"] = stacked_df[\"room_code\"] + stacked_df[\"time_code\"]\nstacked_df['meeting_id'] = pd.factorize(stacked_df['meeting_code'])[0]\n\nday_cols = ['MON-IND','TUE-IND','WED-IND','THU-IND','FRI-IND','SAT-IND','SUN-IND']\nstacked_df[\"mtgs_per_wk\"] = 0\nfor col in day_cols:\n    stacked_df[col] = stacked_df[col].fillna('.')\n    stacked_df['mtgs_per_wk'] = stacked_df[\"mtgs_per_wk\"] + (stacked_df[col] != \".\").astype(int)\n\nstacked_df[\"BEGIN TIME\"] = stacked_df[\"BEGIN TIME\"].replace(\".\",\"0\")\nstacked_df[\"END TIME\"] = stacked_df[\"END TIME\"].replace(\".\",\"0\")\nstacked_df['mtg_length'] = stacked_df[\"END TIME\"].astype(int) - stacked_df[\"BEGIN TIME\"].astype(int)\n\nstacked_df['shared_mtgs_cnt'] =  stacked_df.groupby(['TERM','instructor','time_id'])['time_id'].transform('count')\nstacked_df.loc[(stacked_df['time_code'].isin(['.........'])),'shared_mtgs_cnt'] = 1\n\nstacked_df['mtgs_per_crn'] =  stacked_df.groupby(['TERM','CRN','instructor'])['CRN'].transform('count')\n\n\n\nFind all courses taught by same instructor at the same time\nThis code builds a list of separate courses taught by an instructor at the same time. This code is similar to the code above with the enhancement that it produces an explicit list of courses that share the same room and time.\n\ndef concat_courses(group):\n    return ','.join(group['COURSE'])\n\ntemp_df = pd.DataFrame();\nkeys = ['TERM','instructor','time_code']\ntemp_df[\"concat\"] = stacked_df.groupby(keys).apply(concat_courses,include_groups=False)\ntemp_df[\"list\"] = temp_df[\"concat\"].apply( lambda x :  list(set(x.split(\",\"))) )\ntemp_df[\"combined_count\"] = temp_df[\"list\"].apply( lambda x :  len(x) )\ntemp_df[\"combined_sections\"] = temp_df[\"list\"].apply( lambda x :  \",\".join(x) )\ntemp_df = temp_df.reset_index()\ntemp_df = temp_df[ (temp_df['time_code']!='.........')&(temp_df['combined_count']&gt;1)]\ntemp_df = temp_df[['TERM','instructor','time_code','combined_count','combined_sections']]\nstacked_df = pd.merge(stacked_df,temp_df,left_on=keys, right_on=keys,how=\"left\")\n\n\n\nCGEP: convert to IND rather than LEC from workload perspective\nCardinal Education (formally known as the Commonwealth Graduate Engineering Program (CGEP)) is a collaborative effort among six participating universities and institutions throughout the Commonwealth of Virginia. It utilizes virtual learning classrooms and education technology in synchronous and asynchronous formats to provide working engineers the opportunity to earn a master’s degree in engineering from any of the six participating universities/institutions.\nCGEP courses hosted at VCU are coded as LEC in Banner and must be associated with a VCU instructor. This ensures that the student receives proper credit towards graduation. However, from a workload perspective, these courses do not require local instructor preparation or teaching effort.\nThis section recodes CGEP courses to independent study (IND).\n\n# Function to set the 'TYPE' column based on a string search in 'TITLE'\ndef set_type_based_on_search(row):\n    title = row['TITLE']\n    newtype = row['TYPE']\n    if 'CGEP' in title:\n        newtype = 'IND'\n    return newtype\n\n# Apply the function to the entire DataFrame\nstacked_df['TYPE'] = stacked_df.apply(set_type_based_on_search, axis=1)\n\nNote that additional spare columns are added to persistent instructor and course google sheets.\n\n\nCompute appropriate aggregate measures\nThese measures are used in later calculations for numbers of courses, sections, instructors, etc.\nThese computations are normalized to the appropriate group so that they sum to the correct values when aggregated at the specified group level.\n\n# Create various aggregate columns\nstacked_df['sum_term'] = 1.0 / stacked_df.groupby(['TERM'])['TERM'].transform('count')\nstacked_df['sum_term_crse'] = 1.0 / stacked_df.groupby(['TERM','COURSE'])['COURSE'].transform('count')\nstacked_df['sum_term_crse_crn'] = 1.0 / stacked_df.groupby(['TERM','COURSE','CRN','time_code'])['CRN'].transform('count') / stacked_df['mtgs_per_crn']\nstacked_df['sum_term_crse_crn_mtg_students'] = stacked_df['ACTUAL ENROLLMENT'] * stacked_df['sum_term_crse_crn'] * stacked_df['mtgs_per_crn']\nstacked_df['sum_term_crse_crn_hours'] =  stacked_df['sum_term_crse_crn_mtg_students'] * stacked_df['MAX CREDITS']  / stacked_df['mtgs_per_crn']\n\n\n\nPlaceholder Workload model assignments\nThese are placeholders for any proposed workload model based on course and instructor attributes.\nFor each workload model, there is a:\n\nsum_term_crse_wrkld containing the numeric assignment of workload for that entry in the dataframe.\nwrkld__type* containing the recoded course type. For example, some LEC sections that are actually labs are coded labs. Capstones are also highlighted.\nwrkld_note containing a note about the specific workload assignment.\n\n\nstacked_df['wrkld_sample_type'] = stacked_df['TYPE']\nstacked_df['sum_term_crse_wrkld_sample'] = 0.0\nstacked_df['sum_term_crse_wrkld_sample_lec'] = 0.0\nstacked_df['wrkld_sample_note'] = \"\"\nstacked_df['wrkld_a_type'] = stacked_df['TYPE']\nstacked_df['sum_term_crse_wrkld_a'] = 0.0\nstacked_df['sum_term_crse_wrkld_a_lec'] = 0.0\nstacked_df['wrkld_a_note'] = \"\"\nstacked_df['wrkld_b_type'] = stacked_df['TYPE']\nstacked_df['sum_term_crse_wrkld_b'] = 0.0\nstacked_df['sum_term_crse_wrkld_b_lec'] = 0.0\nstacked_df['wrkld_b_note'] = \"\"\nstacked_df['wrkld_c_type'] = stacked_df['TYPE']\nstacked_df['sum_term_crse_wrkld_c'] = 0.0\nstacked_df['sum_term_crse_wrkld_c_lec'] = 0.0\nstacked_df['wrkld_c_note'] = \"\""
  },
  {
    "objectID": "20_clean.html#sample-workload-model",
    "href": "20_clean.html#sample-workload-model",
    "title": "Cleaning the data",
    "section": "Sample workload model",
    "text": "Sample workload model\nThis is the sample workload model. The assigned faculty workoad will be stored in the sum_term_crse_wrklod_sample field. Here is the model:\n\nmodel_sample = {\n    'base_lecture_value':1.0,\n    'labs_per_lecture':3.0,\n    'vips_per_lecture':3.0,\n    'capstones_per_lecture': 3.0,\n    'students_per_capstone': 4.0,\n    'seminars_per_lecture': 1.0,\n    'res_ind_fld_per_lecture': 0.0,\n    'large_classes': [ [80,1.5],[160,2.0],[240,2.5] ]\n}\n\n\nEach section/CRN is worth a full teaching credit.\nResearch, indepedent study and coop/intern sections receive zero teaching credit in this workload model. Instructors receive credit through their salary if they’re staff. Research active faculty get reduced teaching loads.\nLab sections including actual course labs, capstone/senior design, and VIP receive 1/3 credit. This is consistent with the model that 3 lab hours is equivalent to 1 teaching hour. (e.g., 3-3-4 courses.) NOTE that laboratory sections are NOT coded as separate labs, rather they are coded as LEC making it difficult to discern these. See EGRE306 for an example.\nSeminar sections get full section credit as a positive incentive. There is a limited number of SEM courses, they are important to the curriculum, and we want them covered.\nCapstone designs are scaled to give one LAB (0.33 per above) unit per groups of 4 students.\n\n\nAssign BASE workload to all sections\nAssign base workload to all records. All sections independent of section type start with a base workload of 1.\nAdjust base workload for courses shared by multiple instructors.\nIn some cases, a shared instructor was included in Banner so that the shared instructor could monitor the course in Canvas only, without offering additional teaching effort. In these cases, I recommend adding a “FIX” (listed above) to remove the secondary instructor from the workload data, ensuring that they don’t get credit for a class they aren’t actually co-teaching.\n\n# Assign standard workload : One teaching course shared across multiple instructors\nstacked_df[\"sum_term_crse_wrkld_sample\"] = model_sample['base_lecture_value']\n# Update note\nstacked_df.loc[(stacked_df['wrkld_sample_type']=='LEC'),'wrkld_sample_note'] = \"BASE: [wrkld] \"\n\n# Adjust for multiple instructors\nstacked_df[\"sum_term_crse_wrkld_sample\"] = stacked_df[\"sum_term_crse_wrkld_sample\"] / stacked_df[\"instructor_cnt\"]\n# Update note\nstacked_df.loc[(stacked_df['wrkld_sample_type']=='LEC')&(stacked_df['instructor_cnt']&gt;1.0),'wrkld_sample_note'] = \"BASE: [wrkld] / (2 co-teaching) \"\n\n\n\nAdjust for courses taught at same time by same instructor\n\n# adjust workload for CRN sharing same teaching time\nstacked_df.loc[(stacked_df['shared_mtgs_cnt']&gt;1),'sum_term_crse_wrkld_sample'] = stacked_df.loc[(stacked_df['shared_mtgs_cnt']&gt;1),'sum_term_crse_wrkld_sample'] / stacked_df.loc[(stacked_df['shared_mtgs_cnt']&gt;1),'shared_mtgs_cnt'] \n\n# Update note to reflect adjustment\nstacked_df.loc[(stacked_df['shared_mtgs_cnt']&gt;1),'wrkld_sample_note'] = (\n  stacked_df.loc[(stacked_df['shared_mtgs_cnt']&gt;1),'wrkld_sample_note'] + \"/ \" + \n  stacked_df.loc[(stacked_df['shared_mtgs_cnt']&gt;1),'shared_mtgs_cnt'].astype(str) +\" CRN at same time\"\n)\n\n\n\nAdjust for capstone workloads\nCapstone / senior design courses are coded differently in each department within the college. Further, some of these course numbers change over time (across semesters).\nA list of capstone courses was assembled manually and then applied to convert the capstone sections to CAP.\nThis code is applied in two steps with an opportunity to introduce adjustments to the estimate of capstones.\nIn this sample workload model, estimates of the number of capstones are rounded up (CEIL) to the next highest integer number of capstones.\n\n# Assign CAP workload\n\ncapstones_per_lecture = model_sample['capstones_per_lecture']\nstudents_per_capstone = model_sample['students_per_capstone']\n\nsenior_design_courses = ['CLSC403','EGRB401','EGRB402','CMSC441','CMSC442','CMSC451','CMSC452','EGMN402','EGMN403','ENGR402','ENGR403','EGRE404','EGRE405']\nfor course in senior_design_courses:\n    # Set section type\n    stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['TYPE']=='LAB'),'wrkld_sample_type'] = 'CAP'\n    \n    # Estimate number of capstone sections using load of \"students_per_capstone\". Round up or down.\n    # This code was added after the initial code build, so we're storing the capstone_cnt in one of the spares we created above.\n    stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['wrkld_sample_type']=='CAP'),'capstone_cnt'] = ( 1.0* stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['wrkld_sample_type']=='CAP'),'ACTUAL ENROLLMENT'].astype(float) / students_per_capstone)\n\n    # apply CEIL function\n    stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['wrkld_sample_type']=='CAP'),'capstone_cnt'] = stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['wrkld_sample_type']=='CAP'),'capstone_cnt'].apply( np.ceil )\n\nNow, apply any necessary fixes.\n\n## apply any fixes to number of capstone sections. Use TERM,CRN as keys\n\nNow, actually compute the workload based on the capstone_cnt.\n\nfor course in senior_design_courses:\n    # Using the capstone count above, calculate the capstone workload\n    stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['wrkld_sample_type']=='CAP'),'sum_term_crse_wrkld_sample'] = (\n     stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['wrkld_sample_type']=='CAP'),'sum_term_crse_crn'] / capstones_per_lecture * ( stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['wrkld_sample_type']=='CAP'),'capstone_cnt'] ) )\n\n    # Update note to show adjustments\n    stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['wrkld_sample_type']=='CAP'),'wrkld_sample_note'] = (f\"RULE: [wrkld]={(1.0/capstones_per_lecture):0.2f} for every {students_per_capstone} students in CAP (CAP=\" +\n     stacked_df.loc[(stacked_df['COURSE']==course)&(stacked_df['wrkld_sample_type']=='CAP'),'capstone_cnt'].astype(str) + \")\")\n\n\n\nDistinguish VIP workloads\nVertically Integrated Programs (VIP) provide undergraduate students the opportunity to participate in course-based, multiyear, multidisciplinary, team-based projects under the guidance of faculty and graduate students. These projects are in the faculty areas of expertise, with the main criterion for participation being that of mutual interest.\nManaging a VIP requires effort on the part of the faculty, yet at a lower rate than a standard class.\n\n# Assign VIP workload\n\nvips_per_lecture = model_sample['vips_per_lecture']\n\nstacked_df.loc[stacked_df['course_number'].isin(['497']),'wrkld_sample_type'] = \"VIP\"\nstacked_df.loc[stacked_df['wrkld_sample_type'].isin(['VIP']),'wrkld_sample_note'] = f\"RULE: [wrkld]={(1.0/vips_per_lecture):0.2f} for VIP\"\nstacked_df.loc[(stacked_df['wrkld_sample_type'].isin(['VIP']))&(stacked_df['instructor_cnt']&gt;1.0),'wrkld_sample_note'] = f\"RULE: [wrkld]={(1.0/vips_per_lecture):0.2f} for VIP (co-teaching)\"\nstacked_df.loc[stacked_df['wrkld_sample_type'].isin(['VIP']),'sum_term_crse_wrkld_sample'] = stacked_df.loc[stacked_df['wrkld_sample_type'].isin(['VIP']),'sum_term_crse_wrkld_sample'] / vips_per_lecture\n\n\n\nDistinguish LAB workloads\nLaboratory sections (LAB) are an important part of an engineering and computer science curriculum.\nLAB sections require effort on the part of the faculty member, but at a reduced rate.\nIdentifying lab sections is tricky. The College often codes lab sections differently across departments. Some are coded properly as LAB sections.\nIn other cases, LAB sections are coded as LEC because they share the same CRN as their owner lecture. To capture these cases a special logic is introduced. If a section is taught once per week (e.g., M or W or TH) and the CRN has more than one meeting period, then the section with one meeting period is designated a LAB section.\nIn reviewing the data I found some really odd coding. To accomodate this, I added an override block to turn specific tuples into lab sections. This logic must be maintained manually until the College decides to rework the schedule.\n\n# Assign LAB workload\nlabs_per_lecture = model_sample['labs_per_lecture']\n\n# Assign LAB sections\nstacked_df.loc[(stacked_df['mtgs_per_crn']&gt;1)&(stacked_df['wrkld_sample_type']=='LEC')&(stacked_df['mtgs_per_wk']==1),'wrkld_sample_type'] = 'LAB'\n\n# Apply overrides for LAB sections\n\nfix_stacked(100,\"2x lab mtg\",\n {'TERM':'202410','CRN':12151,'time_code':'.T.R...14511559','instructor':'Abdelwahed,Sherif'},\n {'wrkld_sample_type':'LAB'}\n)\n\n# Create a note for all LAB sections\nstacked_df.loc[stacked_df['wrkld_sample_type'].isin(['LAB']),'wrkld_sample_note'] = f\"RULE: [wrkld]={(1.0/labs_per_lecture):0.2f} for LAB\"\n\n# Assign workload\nstacked_df.loc[stacked_df['wrkld_sample_type'].isin(['LAB']),'sum_term_crse_wrkld_sample'] = stacked_df.loc[stacked_df['wrkld_sample_type'].isin(['LAB']),'sum_term_crse_wrkld_sample'] / labs_per_lecture\n\n# Create a special note for LAB sections that used the special logic to be identified.\nstacked_df.loc[(stacked_df['mtgs_per_crn']&gt;1)&(stacked_df['wrkld_sample_type']=='LAB')&(stacked_df['mtgs_per_wk']==1),'wrkld_sample_note'] = stacked_df.loc[(stacked_df['mtgs_per_crn']&gt;1)&(stacked_df['wrkld_sample_type']=='LAB')&(stacked_df['mtgs_per_wk']==1),'wrkld_sample_note'] + \" (LAB: 1 mtg per wk rule)\"\n\n\n\nDistinguish RES, IND and FLD\nRES, IND and FLD sections are variable unit placeholders in banner that contribute to the full-time status calculation of a student, but don’t necessarily reflect effort of the faculty mentor.\nResearch active faculty are most associated with RES, IND and FLD. To capture the workload we have two options:\n\nWe can associate these units with a non-zero workload value, or\nWe can reduce the workloads of research active faculty.\n\nTo do both would double-count the effort of RES, IND and FLD sections.\nFor purposes of this workload model, we’ll zero these out and let research active faculty have reduced workloads.\n\n# Exclude teaching credit for research (RES), independent study (IND), and intern/coop (FLD).\n# Credit is given for these activities in reduced teaching (research active) or summer pay.\nstacked_df.loc[stacked_df['wrkld_sample_type'].isin(['RES','IND','FLD']),'wrkld_sample_note'] = \"RULE: [wrkld]=0.00 for INS, RES and FLD\"\nstacked_df.loc[stacked_df['wrkld_sample_type'].isin(['RES','IND','FLD']),'sum_term_crse_wrkld_sample'] = model_sample['res_ind_fld_per_lecture']\n\n\n\nDistinguish SEM workloads\nThe seminar class is an important part of our curriculum and requires effort of those organizing the course.\nIn this workload model, the seminar counts as a full workload course.\n\n# Assign SEM workload\n# Ensure that SEM get full credit because we want to reward the faculty member for doing it!\n\nseminars_per_lecture = model_sample['seminars_per_lecture']\n\nstacked_df.loc[stacked_df['wrkld_sample_type'].isin(['SEM']),'wrkld_sample_note'] = f\"RULE: [wrkld] / {seminars_per_lecture} for SEM\"\nstacked_df.loc[(stacked_df['wrkld_sample_type'].isin(['SEM']))&(stacked_df['instructor_cnt']&gt;1.0),'wrkld_sample_note'] = f\"RULE: [wrkld] / {seminars_per_lecture} for SEM (co-teaching)\"\nstacked_df.loc[stacked_df['wrkld_sample_type'].isin(['SEM']),'sum_term_crse_wrkld_sample'] = stacked_df.loc[stacked_df['wrkld_sample_type'].isin(['SEM']),'sum_term_crse_wrkld_sample'] / seminars_per_lecture\n\n\n\nAdjust for large lectures\nLarger lectures require more effort. The code blocks below adjust the base workload for large classes.\n\n#  Process large classes using thresholds and weights in model_sample parameters.\n\nfor threshhold,weight in model_sample['large_classes']:\n    stacked_df.loc[(stacked_df['ACTUAL ENROLLMENT']&gt;=threshhold)&(stacked_df['wrkld_sample_type']=='LEC'),\"sum_term_crse_wrkld_sample\"] = weight / stacked_df[\"instructor_cnt\"]\n    stacked_df.loc[(stacked_df['ACTUAL ENROLLMENT']&gt;=threshhold)&(stacked_df['wrkld_sample_type']=='LEC'),\"wrkld_sample_note\"] = f\"BASE: [wrkld] = {weight} per CRN ENRL&gt;={threshhold}\"\n    stacked_df.loc[(stacked_df['ACTUAL ENROLLMENT']&gt;=threshhold)&(stacked_df['wrkld_sample_type']=='LEC')&(stacked_df['instructor_cnt']&gt;1.0),'wrkld_sample_note'] = f\"BASE: [wrkld]={weight/2.0} per CRN ENRL&gt;={threshhold} (co-teaching)\"\n\n\n\nStore LEC-only workload in separate column.\n\nstacked_df['sum_term_crse_wrkld_sample_lec'] = 0.0\nstacked_df.loc[(stacked_df['wrkld_sample_type']=='LEC'),'sum_term_crse_wrkld_sample_lec'] = stacked_df.loc[(stacked_df['wrkld_sample_type']=='LEC'),'sum_term_crse_wrkld_sample']\n\n# Also, store lecture-only hours (based on workload assignment) to spare value\n\nstacked_df['sum_term_crse_crn_hours_lec'] = 0.0\nstacked_df.loc[(stacked_df['wrkld_sample_type']=='LEC'),'sum_term_crse_crn_hours_lec'] = stacked_df.loc[(stacked_df['wrkld_sample_type']=='LEC'),'sum_term_crse_crn_hours']\n\n\n\nStore list of LECT-only courses\n\ndef list_courses( x ):\n    l = x.unique().tolist()\n    l = list(filter(lambda item: item != \"\", l))\n    return \",\".join(l)\n\ntemp  = stacked_df.copy()\ntemp[\"lec-only-course\"] = \"\"\ntemp.loc[temp['wrkld_sample_type']=='LEC',\"lec-only-course\"] = temp.loc[temp['wrkld_sample_type']=='LEC',\"COURSE\"]\nstacked_df['lec_only_course_list'] = temp.groupby(['TERM','instructor'])['lec-only-course'].transform( list_courses )\n\nstacked_df[(stacked_df['instructor']=='Leonard,John')&(stacked_df['TERM'].isin(['202410','202320']))][['TERM','COURSE','lec_only_course_list']]\n\n\n\n\n\n\n\n\nTERM\nCOURSE\nlec_only_course_list\n\n\n\n\n3007\n202320\nCMSC442\nCMSC475\n\n\n3023\n202320\nCMSC475\nCMSC475\n\n\n3505\n202320\nENGR497\nCMSC475\n\n\n3507\n202320\nENGR497\nCMSC475\n\n\n3691\n202410\nCMSC391\nCMSC391,CMSC508\n\n\n3702\n202410\nCMSC441\nCMSC391,CMSC508\n\n\n3727\n202410\nCMSC508\nCMSC391,CMSC508\n\n\n4175\n202410\nENGR497\nCMSC391,CMSC508\n\n\n4177\n202410\nENGR497\nCMSC391,CMSC508\n\n\n\n\n\n\n\n\n\nSummary\nAt this point the model building is done and the workload assignments are stored in the appropriate columns."
  },
  {
    "objectID": "20_clean.html#examples-checks-and-verifications",
    "href": "20_clean.html#examples-checks-and-verifications",
    "title": "Cleaning the data",
    "section": "Examples, checks and verifications",
    "text": "Examples, checks and verifications\nThe following code blocks are added as unique situations are discovered. The code below shows how these situations are handled and demonstrates how they were corrected.\nAs odd situations are revealed, add a code block here to clearly show the inconsistency. Then, change the workload code above until the situation clears up AND you don’t screw up any of the other situations.\n\nExample: LECT / LAB\nIn this example, a lecture/lab course was coded as 3 separate CRN. Each CRN has a main lecture and a single-meeting-period lab.\nAll three lectures share the same meeting time and are combined into a single workload LECT. Each lab section is assigned 1/3 workload.\nHowever, two of the lab sections share a common meeting time, so they are combined into a single 1/3 workload section.\n\ndef show_block( df,keys,cols):\n    tdf = df\n    for key in keys.keys():\n        tdf = tdf[tdf[key]==keys[key]]\n    return tdf[cols]\n\nshow_block(stacked_df,\n    {'TERM':'202410','COURSE':'EGMN416'},\n    ['COURSE','CRN','TYPE','TITLE','instructor','time_code',\n    'sum_term_crse_crn',\n    'sum_term_crse_crn_mtg_students',\n    'sum_term_crse_crn_hours',\n    'sum_term_crse_wrkld_sample','wrkld_sample_type','wrkld_sample_note']\n)\n\n\n\n\n\n\n\n\nCOURSE\nCRN\nTYPE\nTITLE\ninstructor\ntime_code\nsum_term_crse_crn\nsum_term_crse_crn_mtg_students\nsum_term_crse_crn_hours\nsum_term_crse_wrkld_sample\nwrkld_sample_type\nwrkld_sample_note\n\n\n\n\n4067\nEGMN416\n45899\nLEC\nMECHATRONICS\nHadimani,Ravi\n....F..1400.01650.0\n0.5\n31.0\n46.5\n0.333333\nLAB\nRULE: [wrkld]=0.33 for LAB (LAB: 1 mtg per wk ...\n\n\n4068\nEGMN416\n45899\nLEC\nMECHATRONICS\nHadimani,Ravi\nM...F..1300.01350.0\n0.5\n31.0\n46.5\n0.333333\nLEC\nBASE: [wrkld] / 3.0 CRN at same time\n\n\n4069\nEGMN416\n32709\nLEC\nMECHATRONICS\nHadimani,Ravi\nM......1400.01650.0\n0.5\n30.0\n45.0\n0.166667\nLAB\nRULE: [wrkld]=0.33 for LAB (LAB: 1 mtg per wk ...\n\n\n4070\nEGMN416\n32709\nLEC\nMECHATRONICS\nHadimani,Ravi\nM...F..1300.01350.0\n0.5\n30.0\n45.0\n0.333333\nLEC\nBASE: [wrkld] / 3.0 CRN at same time\n\n\n4071\nEGMN416\n46922\nLEC\nMECHATRONICS\nHadimani,Ravi\nM......1400.01650.0\n0.5\n29.0\n43.5\n0.166667\nLAB\nRULE: [wrkld]=0.33 for LAB (LAB: 1 mtg per wk ...\n\n\n4072\nEGMN416\n46922\nLEC\nMECHATRONICS\nHadimani,Ravi\nM...F..1300.01350.0\n0.5\n29.0\n43.5\n0.333333\nLEC\nBASE: [wrkld] / 3.0 CRN at same time\n\n\n\n\n\n\n\n\nsum_term_crse_crn represents the number of unique CRNs. This value is split across multiple meeting times per CRN.\nsum_term_crse_crn_mtg_students represents the number of students in each crn-meeting time. This value is useful to determine how many students are in any given meeting time.\nsum_term_crse_crn_hours represents the number of credit hours associated with a CRN. This value is split across multiple meeting times.\n\n\n\nExample: LECT sharing a common time\nIn this example, two CRN are sharing a common teaching time and their workloads are split across the two CRN.\n\nshow_block(stacked_df,\n    {'TERM':'202320','instructor':\"Heise,Rebecca\"},\n    ['COURSE','CRN','TYPE','TITLE','instructor','time_code','sum_term_crse_wrkld_sample','wrkld_sample_type','wrkld_sample_note']\n)\n\n\n\n\n\n\n\n\nCOURSE\nCRN\nTYPE\nTITLE\ninstructor\ntime_code\nsum_term_crse_wrkld_sample\nwrkld_sample_type\nwrkld_sample_note\n\n\n\n\n3079\nEGRB111\n43476\nLEC\nINTRO TO BIOL SYS ENGINEERING\nHeise,Rebecca\nM.W.F..900.0950.0\n1.0\nLEC\nBASE: [wrkld]\n\n\n3101\nEGRB411\n40539\nLEC\nCELL MECHANICS & MECHANOBIOL\nHeise,Rebecca\nM.W.F..1000.01050.0\n0.5\nLEC\nBASE: [wrkld] / 2.0 CRN at same time\n\n\n3105\nEGRB491\n45797\nLEC\nST: PULMONARY LAB RESEARCH\nHeise,Rebecca\n.........\n1.0\nLEC\nBASE: [wrkld]\n\n\n3107\nEGRB517\n40540\nLEC\nCELL MECHANICS & MECHANOBIOLOG\nHeise,Rebecca\nM.W.F..1000.01050.0\n0.5\nLEC\nBASE: [wrkld] / 2.0 CRN at same time\n\n\n3115\nEGRB697\n28942\nRES\nDIRECTED RES IN BIOMEDICAL EGR\nHeise,Rebecca\n.........\n0.0\nRES\nRULE: [wrkld]=0.00 for INS, RES and FLD\n\n\n3122\nEGRB697\n45891\nRES\nDIRECTED RES IN BIOMEDICAL EGR\nHeise,Rebecca\n.........\n0.0\nRES\nRULE: [wrkld]=0.00 for INS, RES and FLD\n\n\n3145\nEGRB697\n28930\nRES\nDIRECTED RES IN BIOMEDICAL EGR\nHeise,Rebecca\n.........\n0.0\nRES\nRULE: [wrkld]=0.00 for INS, RES and FLD\n\n\n3146\nEGRB697\n28934\nRES\nDIRECTED RES IN BIOMEDICAL EGR\nHeise,Rebecca\n.........\n0.0\nRES\nRULE: [wrkld]=0.00 for INS, RES and FLD\n\n\n3147\nEGRB697\n45890\nRES\nDIRECTED RES IN BIOMEDICAL EGR\nHeise,Rebecca\n.........\n0.0\nRES\nRULE: [wrkld]=0.00 for INS, RES and FLD\n\n\n3541\nENGR701\n43901\nRES\nPOST-CANDIDACY DOCT RESEARCH\nHeise,Rebecca\n.........\n0.0\nRES\nRULE: [wrkld]=0.00 for INS, RES and FLD\n\n\n\n\n\n\n\n\n\nExample: Miscode?\nThis record shows two CRN overlapping in teaching time, but not exactly matching teaching times. Is this for real? Is this a miscode? My initial guess is that this is a miscode and the times should be corrected. This can be accomplished with a FIX record above.\n\nshow_block(stacked_df,\n    {'TERM':'202310','instructor':\"Ferri,James\"},\n    ['COURSE','CRN','TYPE','TITLE','instructor','time_code','MODALITY CODE','sum_term_crse_wrkld_sample','wrkld_sample_type','wrkld_sample_note']\n)\n\n\n\n\n\n\n\n\nCOURSE\nCRN\nTYPE\nTITLE\ninstructor\ntime_code\nMODALITY CODE\nsum_term_crse_wrkld_sample\nwrkld_sample_type\nwrkld_sample_note\n\n\n\n\n2636\nCLSE301\n42633\nLEC\nTRANSPORT PHENOMENA I\nFerri,James\n.T.R...1530.01645.0\nRINP\n1.0\nLEC\nBASE: [wrkld]\n\n\n2648\nCLSE585\n44879\nLEC\nINTERFACIAL PHENOMENA\nFerri,James\n..W....1700.01930.0\nRINP\n1.0\nLEC\nBASE: [wrkld]\n\n\n2660\nCLSE697\n37469\nRES\nDIRECTED RESEARCH\nFerri,James\n.........\nRINS\n0.0\nRES\nRULE: [wrkld]=0.00 for INS, RES and FLD\n\n\n2667\nCLSE697\n37073\nRES\nDIRECTED RESEARCH\nFerri,James\n.........\nRINS\n0.0\nRES\nRULE: [wrkld]=0.00 for INS, RES and FLD\n\n\n2941\nENGR591\n44935\nLEC\nTOP: SYSTEMS ENGINEERING I\nFerri,James\n.........\nRONA\n1.0\nLEC\nBASE: [wrkld]\n\n\n2949\nENGR691\n44989\nLEC\nST:ADV TOP IN INTERFACIAL PHEN\nFerri,James\n..W....1700.01900.0\nRINP\n1.0\nLEC\nBASE: [wrkld]\n\n\n2954\nENGR701\n43323\nRES\nPOST-CANDIDACY DOCT RESEARCH\nFerri,James\n.........\nRINS\n0.0\nRES\nRULE: [wrkld]=0.00 for INS, RES and FLD\n\n\n\n\n\n\n\n\n\nExample: Singleton ROND\nThis shows a singleton ROND sections. Synchronous on-line sections (ROND) should always be taught with an in-person section. In this case I can only imagine that no students enrolled in the RINP/face-to-face section and it was dropped during earlier data cleaning.\n\nshow_block(stacked_df,\n    {'TERM':'202320','instructor':\"Manic,Milos\"},\n    ['COURSE','CRN','TYPE','TITLE','instructor','time_code','MODALITY CODE','sum_term_crse_wrkld_sample','wrkld_sample_type','wrkld_sample_note']\n)\n\n\n\n\n\n\n\n\nCOURSE\nCRN\nTYPE\nTITLE\ninstructor\ntime_code\nMODALITY CODE\nsum_term_crse_wrkld_sample\nwrkld_sample_type\nwrkld_sample_note\n\n\n\n\n3036\nCMSC636\n44831\nLEC\nNEURAL NETS AND DEEP LEARNING\nManic,Milos\nM.W....1200.01315.0\nROND\n1.000000\nLEC\nBASE: [wrkld]\n\n\n3052\nCMSC697\n36849\nRES\nDIRECTED RESEARCH\nManic,Milos\n.........\nRINS\n0.000000\nRES\nRULE: [wrkld]=0.00 for INS, RES and FLD\n\n\n3053\nCMSC697\n36851\nRES\nDIRECTED RESEARCH\nManic,Milos\n.........\nRINS\n0.000000\nRES\nRULE: [wrkld]=0.00 for INS, RES and FLD\n\n\n3510\nENGR497\n45526\nLAB\nVERTICALLY INTEGRATED PROJECTS\nManic,Milos\n.........\nRINS\n0.333333\nVIP\nRULE: [wrkld]=0.33 for VIP\n\n\n3511\nENGR497\n45527\nLAB\nVERTICALLY INTEGRATED PROJECTS\nManic,Milos\n.........\nRINS\n0.333333\nVIP\nRULE: [wrkld]=0.33 for VIP\n\n\n\n\n\n\n\n\n\nExample: Doubleton ROND+RINP\nThis second example shows a doubleton ROND+RINP section.\n\nshow_block(stacked_df,\n    {'TERM':'202410','instructor':\"Ghosh,Preetam\"},\n    ['COURSE','CRN','TYPE','TITLE','instructor','time_code','MODALITY CODE','sum_term_crse_wrkld_sample','wrkld_sample_type','wrkld_sample_note']\n)\n\n\n\n\n\n\n\n\nCOURSE\nCRN\nTYPE\nTITLE\ninstructor\ntime_code\nMODALITY CODE\nsum_term_crse_wrkld_sample\nwrkld_sample_type\nwrkld_sample_note\n\n\n\n\n3703\nCMSC441\n43750\nLAB\nSR DESIGN STUDIO I (LAB/PROJ)\nGhosh,Preetam\n.........\nRONL\n0.666667\nCAP\nRULE: [wrkld]=0.33 for every 4.0 students in C...\n\n\n3725\nCMSC502\n37708\nLEC\nPARALLEL ALGORITHMS\nGhosh,Preetam\n.T.R...1530.01645.0\nRINP\n0.500000\nLEC\nBASE: [wrkld] / 2.0 CRN at same time\n\n\n3726\nCMSC502\n37709\nLEC\nPARALLEL ALGORITHMS\nGhosh,Preetam\n.T.R...1530.01645.0\nROND\n0.500000\nLEC\nBASE: [wrkld] / 2.0 CRN at same time\n\n\n3751\nCMSC697\n37384\nRES\nDIRECTED RESEARCH\nGhosh,Preetam\n.........\nRINS\n0.000000\nRES\nRULE: [wrkld]=0.00 for INS, RES and FLD\n\n\n3752\nCMSC697\n37385\nRES\nDIRECTED RESEARCH\nGhosh,Preetam\n.........\nRINS\n0.000000\nRES\nRULE: [wrkld]=0.00 for INS, RES and FLD\n\n\n3753\nCMSC697\n37386\nRES\nDIRECTED RESEARCH\nGhosh,Preetam\n.........\nRINS\n0.000000\nRES\nRULE: [wrkld]=0.00 for INS, RES and FLD\n\n\n4211\nENGR701\n46939\nRES\nPOST-CANDIDACY DOCT RESEARCH\nGhosh,Preetam\n.........\nRINS\n0.000000\nRES\nRULE: [wrkld]=0.00 for INS, RES and FLD\n\n\n\n\n\n\n\n\n\nExample: odd counting\nVerifying actual enrollment vs sum_term_crse_wrkld_sample\n\nshow_block(stacked_df,\n    {'TERM':'202410','instructor':\"Duke,Debra\",'COURSE':'CMSC256'},\n    ['COURSE','CRN','TYPE','TITLE','instructor','time_code','MODALITY CODE','ACTUAL ENROLLMENT','MAX CREDITS','time_code','sum_term_crse_crn_mtg_students','sum_term_crse_crn_hours',\n    'sum_term_crse_wrkld_sample','wrkld_sample_type','wrkld_sample_note']\n)\n\n\n\n\n\n\n\n\nCOURSE\nCRN\nTYPE\nTITLE\ninstructor\ntime_code\nMODALITY CODE\nACTUAL ENROLLMENT\nMAX CREDITS\ntime_code\nsum_term_crse_crn_mtg_students\nsum_term_crse_crn_hours\nsum_term_crse_wrkld_sample\nwrkld_sample_type\nwrkld_sample_note\n\n\n\n\n3670\nCMSC256\n36067\nLEC\nDATA STRUCTURE & OBJECT PROG\nDuke,Debra\n..W....1300.01450.0\nRONB\n83\n4.0\n..W....1300.01450.0\n83.0\n166.0\n0.333333\nLAB\nRULE: [wrkld]=0.33 for LAB (LAB: 1 mtg per wk ...\n\n\n3671\nCMSC256\n36067\nLEC\nDATA STRUCTURE & OBJECT PROG\nDuke,Debra\n.T.R...1230.01345.0\nRONB\n83\n4.0\n.T.R...1230.01345.0\n83.0\n166.0\n1.500000\nLEC\nBASE: [wrkld] = 1.5 per CRN ENRL&gt;=80\n\n\n3672\nCMSC256\n41689\nLEC\nDATA STRUCTURE & OBJECT PROG\nDuke,Debra\n..W....1600.01750.0\nROND\n31\n4.0\n..W....1600.01750.0\n31.0\n62.0\n0.333333\nLAB\nRULE: [wrkld]=0.33 for LAB (LAB: 1 mtg per wk ...\n\n\n3673\nCMSC256\n41689\nLEC\nDATA STRUCTURE & OBJECT PROG\nDuke,Debra\n.T.R...1600.01715.0\nROND\n31\n4.0\n.T.R...1600.01715.0\n31.0\n62.0\n1.000000\nLEC\nBASE: [wrkld]\n\n\n\n\n\n\n\n\n\nExample: odd counting\nVerifying actual enrollment vs sum_term_crse_wrkld_sample\n\nshow_block(stacked_df,\n    {'TERM':'202410','instructor':\"Duke,Debra\",'COURSE':'CMSC256'},\n    ['COURSE','CRN','TYPE','TITLE','instructor','time_code','MODALITY CODE','ACTUAL ENROLLMENT','MAX CREDITS','time_code','sum_term_crse_crn_mtg_students','sum_term_crse_crn_hours',\n    'sum_term_crse_wrkld_sample','wrkld_sample_type','wrkld_sample_note']\n)\n\n\n\n\n\n\n\n\nCOURSE\nCRN\nTYPE\nTITLE\ninstructor\ntime_code\nMODALITY CODE\nACTUAL ENROLLMENT\nMAX CREDITS\ntime_code\nsum_term_crse_crn_mtg_students\nsum_term_crse_crn_hours\nsum_term_crse_wrkld_sample\nwrkld_sample_type\nwrkld_sample_note\n\n\n\n\n3670\nCMSC256\n36067\nLEC\nDATA STRUCTURE & OBJECT PROG\nDuke,Debra\n..W....1300.01450.0\nRONB\n83\n4.0\n..W....1300.01450.0\n83.0\n166.0\n0.333333\nLAB\nRULE: [wrkld]=0.33 for LAB (LAB: 1 mtg per wk ...\n\n\n3671\nCMSC256\n36067\nLEC\nDATA STRUCTURE & OBJECT PROG\nDuke,Debra\n.T.R...1230.01345.0\nRONB\n83\n4.0\n.T.R...1230.01345.0\n83.0\n166.0\n1.500000\nLEC\nBASE: [wrkld] = 1.5 per CRN ENRL&gt;=80\n\n\n3672\nCMSC256\n41689\nLEC\nDATA STRUCTURE & OBJECT PROG\nDuke,Debra\n..W....1600.01750.0\nROND\n31\n4.0\n..W....1600.01750.0\n31.0\n62.0\n0.333333\nLAB\nRULE: [wrkld]=0.33 for LAB (LAB: 1 mtg per wk ...\n\n\n3673\nCMSC256\n41689\nLEC\nDATA STRUCTURE & OBJECT PROG\nDuke,Debra\n.T.R...1600.01715.0\nROND\n31\n4.0\n.T.R...1600.01715.0\n31.0\n62.0\n1.000000\nLEC\nBASE: [wrkld]"
  },
  {
    "objectID": "20_clean.html#store-the-dataframe",
    "href": "20_clean.html#store-the-dataframe",
    "title": "Cleaning the data",
    "section": "Store the dataframe",
    "text": "Store the dataframe\nWe’re storing both the stacked and unstacked data. Note that the aggregate measures are stored with the stacked data only.\n\nStore to a local CSV file\n\n# Store as CSV files\nsections_df.to_csv('sections_df.csv', index=False)\nstacked_df.to_csv('stacked_df.csv', index=False)\n\n\n\nStore the data in google sheets\n\n# Open the worksheet \nspreadsheet_key = \"1ZK7k8M85CXLof6FdeJYJuGFbfjsOXrCv5mc7OgUInWw\"\nworksheet_name = \"Source data\"\n\ndata_to_write = stacked_df.to_records(index=False)\ntry:\n    sheet = client.open_by_key(spreadsheet_key).worksheet(worksheet_name)\nexcept SpreadsheetNotFound as e:\n    sheet = client.open_by_key(spreadsheet_key).add_worksheet( \n        title = worksheet_name,nrows=100,ncols=10\n    )\nexcept APIError as e:\n    if 'insufficient permissions' in str(e).lower():\n        print(f\"Permission denied error: {e}\")\n        raise PermissionError(f\"Permission denied: {e}\")  # Creating a new PermissionError\n    else:\n        print(f\"Failed to fetch data due to API error: {e}\")\n    raise\nexcept ValueError as e:\n    print(f\"Data retrieval issue: {e}\")\n    raise\nexcept Exception as e:\n    # A generic catch-all to handle unexpected errors\n    print(f\"An unexpected error occurred: {e}\")\n    raise\n\n\ntry:\n    sheet.clear()\n    set_with_dataframe(worksheet=sheet, dataframe=stacked_df, include_index=False,include_column_header=True, resize=True)\nexcept:\n    print(f\"Data can't be written\")\n\n\n\nFreshen persistent instructor data\nThis block identifies any instructors not found in the persistent instructor data and adds them to the list with default values.\nThis code is not working yet. It should be fixed when a new semester is added and new instructors and courses are discovered in the imported worksheets.\n\n#worksheet_name = \"Instructor data\"\n#summary_df = stacked_df.groupby('instructor')[['COLLEGE','DEPT']].apply(lambda x: x.mode().iloc[0]).#reset_index()\n#summary_df = summary_df.sort_values(by=['COLLEGE','DEPT','instructor'])\n#data_to_write = summary_df.to_records(index=False)\n#try:\n#    sheet = client.open_by_key(spreadsheet_key).worksheet(worksheet_name)\n#except:\n#    nrows,ncols = summary_df.shape\n#    sheet = client.open_by_key(spreadsheet_key).add_worksheet( \n#        title = worksheet_name,rows=nrows+1,cols=ncols+1\n#    )\n#sheet.clear()\n#set_with_dataframe(worksheet=sheet, dataframe=summary_df, include_index=False,include_column_header=True, resize=True)\n\n# Find names in df2 that are not in df1\n##names_to_add = df2[~df2['name'].isin(df1['name'])]\n\n# Add the rows with missing names from df2 to df1\n## df1 = pd.concat([df1, names_to_add], ignore_index=True)"
  },
  {
    "objectID": "20_clean.html#summary-1",
    "href": "20_clean.html#summary-1",
    "title": "Cleaning the data",
    "section": "Summary",
    "text": "Summary\nThat’s all folks! Additional models can be added and the google sheets can be reviewed.\nNow the real analysis can begin:\n\nhere is a link to a google sheet that shows tables created from the dataframe.\nhere is a HTML report that is still evolving.\nhere is the CSV for the cleaned dataframe. This dataframe contains one tuple per (TERM,CRN,INSTRUCTOR,MEETING_CODE)."
  },
  {
    "objectID": "10_download.html",
    "href": "10_download.html",
    "title": "Downloading the data",
    "section": "",
    "text": "Data were pulled from the VCU Reporting Center in the Staff | Course Schedule Report as shown below:\nReports are run by semester for the College of Engineering and stored in separate files. Care should be taken to open each file after it’s been saved and RESAVE the file into XLSX format.\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe files are named appropriately and stored in the data folder in this repository.\n\n\n\n\n\nFile name\nTerm Code\nAcad Year\nPeriod Code\nPeriod Name\n\n\n\n\nVCU-SOC-202110-FA2020.xlsx\n202110\nAY20-21\nFA2020\nFall 2020\n\n\nVCU-SOC-202120-SP2021.xlsx\n202120\nAY20-21\nSP2021\nSpring 2021\n\n\nVCU-SOC-202130-SU2021.xlsx\n202130\nAY20-21\nSU2021\nSummer 2021\n\n\nVCU-SOC-202210-FA2021.xlsx\n202210\nAY21-22\nFA2021\nFall 2021\n\n\nVCU-SOC-202220-SP2022.xlsx\n202220\nAY21-22\nSP2022\nSpring 2022\n\n\nVCU-SOC-202230-SU2022.xlsx\n202230\nAY21-22\nSU2022\nSummer 2022\n\n\nVCU-SOC-202310-FA2022.xlsx\n202310\nAY22-23\nFA2022\nFall 2022\n\n\nVCU-SOC-202320-SP2023.xlsx\n202320\nAY22-23\nSP2023\nSpring 2023\n\n\nVCU-SOC-202330-SU2023.xlsx\n202330\nAY22-23\nSU2023\nSummer 2023\n\n\nVCU-SOC-202410-FA2023.xlsx\n202410\nAY23-24\nFA2023\nFall 2023\n\n\nVCU-SOC-202420-SP2024.xlsx\n202420\nAY23-24\nSP2024\nSpring 2024\n\n\nVCU-SOC-202430-SU2024.xlsx\n202430\nAY23-24\nSU2024\nSummer 2024\n\n\nVCU-SOC-202510-FA2024.xlsx\n202510\nAY24-25\nFA2024\nFall 2024\n\n\n\n\n\nThese data are difficult to work in separate files and often contain incorrect or inconsistent data. A significant process of data cleaning was undertaken prior to computing workloads."
  },
  {
    "objectID": "10_download.html#data-sources",
    "href": "10_download.html#data-sources",
    "title": "Downloading the data",
    "section": "",
    "text": "Data were pulled from the VCU Reporting Center in the Staff | Course Schedule Report as shown below:\nReports are run by semester for the College of Engineering and stored in separate files. Care should be taken to open each file after it’s been saved and RESAVE the file into XLSX format.\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe files are named appropriately and stored in the data folder in this repository.\n\n\n\n\n\nFile name\nTerm Code\nAcad Year\nPeriod Code\nPeriod Name\n\n\n\n\nVCU-SOC-202110-FA2020.xlsx\n202110\nAY20-21\nFA2020\nFall 2020\n\n\nVCU-SOC-202120-SP2021.xlsx\n202120\nAY20-21\nSP2021\nSpring 2021\n\n\nVCU-SOC-202130-SU2021.xlsx\n202130\nAY20-21\nSU2021\nSummer 2021\n\n\nVCU-SOC-202210-FA2021.xlsx\n202210\nAY21-22\nFA2021\nFall 2021\n\n\nVCU-SOC-202220-SP2022.xlsx\n202220\nAY21-22\nSP2022\nSpring 2022\n\n\nVCU-SOC-202230-SU2022.xlsx\n202230\nAY21-22\nSU2022\nSummer 2022\n\n\nVCU-SOC-202310-FA2022.xlsx\n202310\nAY22-23\nFA2022\nFall 2022\n\n\nVCU-SOC-202320-SP2023.xlsx\n202320\nAY22-23\nSP2023\nSpring 2023\n\n\nVCU-SOC-202330-SU2023.xlsx\n202330\nAY22-23\nSU2023\nSummer 2023\n\n\nVCU-SOC-202410-FA2023.xlsx\n202410\nAY23-24\nFA2023\nFall 2023\n\n\nVCU-SOC-202420-SP2024.xlsx\n202420\nAY23-24\nSP2024\nSpring 2024\n\n\nVCU-SOC-202430-SU2024.xlsx\n202430\nAY23-24\nSU2024\nSummer 2024\n\n\nVCU-SOC-202510-FA2024.xlsx\n202510\nAY24-25\nFA2024\nFall 2024\n\n\n\n\n\nThese data are difficult to work in separate files and often contain incorrect or inconsistent data. A significant process of data cleaning was undertaken prior to computing workloads."
  },
  {
    "objectID": "30_explore.html",
    "href": "30_explore.html",
    "title": "Exploring the data",
    "section": "",
    "text": "For this analysis we’ll be using the stacked_df data frame from the cleaning process.\nI haven’t spend much time on this. My effort to date has been spent on developing and documenting the preparing of the data at the instructor level.\nSignificant effort was also invested in the corresponding google workbook."
  },
  {
    "objectID": "30_explore.html#columns-in-the-dataframe",
    "href": "30_explore.html#columns-in-the-dataframe",
    "title": "Exploring the data",
    "section": "Columns in the dataframe",
    "text": "Columns in the dataframe\n\n# Load the CSV file into a pandas data frame.\n\nstacked_df = pd.read_csv('stacked_df.csv')\n\n# Ensure that these 3 columns are treated as strings and not as numbers.\nfor col in ['TERM','COURSE','SECT']:\n  stacked_df[col] = stacked_df[col].astype(str)\n\n# Print a list of columns\nstacked_df.columns\n\nIndex(['TERM', 'PART_OF_TERM', 'COLLEGE', 'DEPT', 'COURSE', 'SECT', 'CRN',\n       'TYPE', 'MIN CREDITS', 'MAX CREDITS',\n       ...\n       'sum_term_crse_wrkld_a_lec', 'wrkld_a_note', 'wrkld_b_type',\n       'sum_term_crse_wrkld_b', 'sum_term_crse_wrkld_b_lec', 'wrkld_b_note',\n       'wrkld_c_type', 'sum_term_crse_wrkld_c', 'sum_term_crse_wrkld_c_lec',\n       'wrkld_c_note'],\n      dtype='object', length=104)"
  },
  {
    "objectID": "30_explore.html#college-wide-measures-over-time",
    "href": "30_explore.html#college-wide-measures-over-time",
    "title": "Exploring the data",
    "section": "College-wide measures over time",
    "text": "College-wide measures over time\nThis table presents a summary of courses (e.g., CMSC 255, CMSC 355, etc.), sections (or CRN), and student enrollments by semester in our data file.\n\n\n\n\n\nTerm\nTerm Name\nCourse Sum\nCRN Sum\nStuMtg Sum\nHours Sum\n\n\n\n\n202110\nFall 2020\n149\n419\n7967\n16353\n\n\n202120\nSpring 2021\n137\n445\n7393\n16518\n\n\n202130\nSummer 2021\n25\n112\n586\n1444\n\n\n202210\nFall 2021\n154\n425\n7362\n16689\n\n\n202220\nSpring 2022\n146\n449\n7327\n16801\n\n\n202230\nSummer 2022\n29\n105\n624\n1341\n\n\n202310\nFall 2022\n159\n438\n8306\n18396\n\n\n202320\nSpring 2023\n146\n458\n7692\n17790\n\n\n202330\nSummer 2023\n25\n104\n564\n1213\n\n\n202410\nFall 2023\n157\n452\n9497\n21298\n\n\n202420\nSpring 2024\n154\n466\n8735\n20358\n\n\n202430\nSummer 2024\n25\n92\n552\n1317\n\n\n202510\nFall 2024\n163\n0\n0\n0"
  },
  {
    "objectID": "30_explore.html#teaching-for-fall-2023-by-subject",
    "href": "30_explore.html#teaching-for-fall-2023-by-subject",
    "title": "Exploring the data",
    "section": "Teaching for Fall 2023 by subject",
    "text": "Teaching for Fall 2023 by subject\n\n\n\n\n\nDept\nCourse Sum\nCRN Sum\nStudent Sum\nHours Sum\n\n\n\n\nCMSC\n35\n95\n3552\n9235\n\n\nEGRB\n31\n65\n994\n2287\n\n\nEGRC\n14\n40\n432\n1021\n\n\nEGRE\n32\n70\n1488\n2803\n\n\nEGRM\n32\n103\n2215\n4925\n\n\nENGR\n13\n79\n816\n1027"
  },
  {
    "objectID": "35_explore2.html",
    "href": "35_explore2.html",
    "title": "Exploring instructor measures",
    "section": "",
    "text": "For this analysis we’ll be using the stacked_df data frame from the cleaning process.\nI haven’t spend much time on this. My effort to date has been spent on developing and documenting the preparing of the data at the instructor level.\nSignificant effort was also invested in the corresponding google workbook.\nHUYEN - In the workbook above:"
  },
  {
    "objectID": "35_explore2.html#columns-in-the-dataframe",
    "href": "35_explore2.html#columns-in-the-dataframe",
    "title": "Exploring instructor measures",
    "section": "Columns in the dataframe",
    "text": "Columns in the dataframe\nLoad the data frame. The OJS code would like slightly different.\n\n# Load the data frame\nstacked_df = pd.read_csv('stacked_df.csv')\n\n# Strip whitespace from column names\nstacked_df.columns = stacked_df.columns.str.strip()\n\n# Force types of these columns to be strings\nfor col in ['TERM','COURSE','SECT']:\n  stacked_df[col] = stacked_df[col].astype(str)\n\n# print the columns.  Pandas will display an abbreviated table.\nprint(stacked_df.columns)\n\nIndex(['TERM', 'PART_OF_TERM', 'COLLEGE', 'DEPT', 'COURSE', 'SECT', 'CRN',\n       'TYPE', 'MIN CREDITS', 'MAX CREDITS',\n       ...\n       'sum_term_crse_wrkld_a_lec', 'wrkld_a_note', 'wrkld_b_type',\n       'sum_term_crse_wrkld_b', 'sum_term_crse_wrkld_b_lec', 'wrkld_b_note',\n       'wrkld_c_type', 'sum_term_crse_wrkld_c', 'sum_term_crse_wrkld_c_lec',\n       'wrkld_c_note'],\n      dtype='object', length=104)"
  },
  {
    "objectID": "35_explore2.html#college-wide-measures-over-time",
    "href": "35_explore2.html#college-wide-measures-over-time",
    "title": "Exploring instructor measures",
    "section": "College-wide measures over time",
    "text": "College-wide measures over time\nKey measures for these data include:\n\nNumber of Courses : A course is designed by a course number, for example, CMSC 508 or CMSC 210 or CMSC 355. In the table below, we present the sum of unique course numbers.\nNumber of CRNs : A CRN is a “course reference number”. Often a single course will be coded in Banner using multiple CRNS, one for each unique meeting time/place. The CRN SUM column presents the sum of individual CRNs.\nStuMtgSum : number of individual student meetings. Student enroll in CRNs, not courses. The stumtgsum measure represents the sum of students across all CRN. Depending on how a course is coded, this may double count students in an individual course.\nHours Sum : There are several ways to calculate this variable. In general, this is calculated on a PER CRN basis, multiplying the unique headcount in the CRN time the credit-hour value of a course (usually, 2, 3 or 4).\n\nThe table below shows these key measures accumulated by all semesters in the data set.\n\n# Create my four desired columns\n\n# lecture hours and non-lecture hours\nstacked_df['sum_term_crse_crn_hours_lec'] = 0.0\nstacked_df['sum_term_crse_crn_hours_non_lec'] = 0.0\nstacked_df.loc[stacked_df['wrkld_sample_type'] == 'LEC', 'sum_term_crse_crn_hours_lec'] = stacked_df['sum_term_crse_crn_hours']\nstacked_df.loc[stacked_df['wrkld_sample_type'] != 'LEC', 'sum_term_crse_crn_hours_non_lec'] = stacked_df['sum_term_crse_crn_hours']\n\n# lecture workload and non-lecture workload\nstacked_df['sum_term_crse_wrkld_sample_lec'] = stacked_df['sum_term_crse_wrkld_sample_lec']\nstacked_df['sum_term_crse_wrkld_sample_non_lec'] = stacked_df['sum_term_crse_wrkld_sample'] - stacked_df['sum_term_crse_wrkld_sample_lec']\n\n\nsummary_df = stacked_df.groupby(['TERM','period_name']).agg(\n  {'sum_term_crse':'sum',\n  'sum_term_crse_crn':'sum',\n  'sum_term_crse_crn_mtg_students':'sum',\n  'sum_term_crse_wrkld_sample_lec':'sum',\n  'sum_term_crse_wrkld_sample':'sum',\n  'sum_term_crse_crn_hours':'sum'}).reset_index()\n\nMarkdown(tabulate(\n  summary_df, \n  headers=['Term','Term Name','Course Sum','CRN Sum','StuMtg Sum','Hours Sum'],\n  numalign=\"right\",stralign=\"left\",\n  showindex=False,\n  floatfmt=\".0f\"  # Format numbers without decimals\n))\n\n\n\n\n\n\nTerm\nTerm Name\nCourse Sum\nCRN Sum\nStuMtg Sum\nHours Sum\n\n\n\n\n202110\nFall 2020\n149\n419\n7967\n184\n248\n16353\n\n\n202120\nSpring 2021\n137\n445\n7393\n147\n207\n16518\n\n\n202130\nSummer 2021\n25\n112\n586\n13\n14\n1444\n\n\n202210\nFall 2021\n154\n425\n7362\n172\n228\n16689\n\n\n202220\nSpring 2022\n146\n449\n7327\n156\n218\n16801\n\n\n202230\nSummer 2022\n29\n105\n624\n15\n17\n1341\n\n\n202310\nFall 2022\n159\n438\n8306\n157\n225\n18396\n\n\n202320\nSpring 2023\n146\n458\n7692\n140\n212\n17790\n\n\n202330\nSummer 2023\n25\n104\n564\n18\n19\n1213\n\n\n202410\nFall 2023\n157\n452\n9497\n162\n237\n21298\n\n\n202420\nSpring 2024\n154\n466\n8735\n162\n240\n20358\n\n\n202430\nSummer 2024\n25\n92\n552\n19\n20\n1317\n\n\n202510\nFall 2024\n163\n0\n0\n0\n0\n0"
  },
  {
    "objectID": "35_explore2.html#aggregate-measures-over-all-semesters",
    "href": "35_explore2.html#aggregate-measures-over-all-semesters",
    "title": "Exploring instructor measures",
    "section": "Aggregate measures over all semesters",
    "text": "Aggregate measures over all semesters"
  },
  {
    "objectID": "35_explore2.html#instructor-measures-for-spring-2023-and-fall-2023.",
    "href": "35_explore2.html#instructor-measures-for-spring-2023-and-fall-2023.",
    "title": "Exploring instructor measures",
    "section": "Instructor measures for Spring 2023 and Fall 2023.",
    "text": "Instructor measures for Spring 2023 and Fall 2023.\n\n# Filter stacked data frame for the two desired terms and desired department\ndf = stacked_df[stacked_df['TERM'].isin(['202320','202410'])]\ndf = df[df['DEPT'].isin(['CMSC'])]\n\n# Create summary data frame by instructor for key measures.\nsummary_df = df.groupby(['instructor']).agg({\n  'sum_term_crse':'sum',\n  'sum_term_crse_crn_hours':'sum',\n  'sum_term_crse_wrkld_sample_lec':'sum',\n  'sum_term_crse_wrkld_sample_non_lec':'sum',\n  'sum_term_crse_crn_hours_lec':'sum',\n  'sum_term_crse_crn_hours_non_lec':'sum'\n  }).reset_index()\n\n# Sort in descending order by credit hours\nsummary_df = summary_df.sort_values(by='sum_term_crse_crn_hours', ascending=False)\nprint(summary_df)\n\n                 instructor  sum_term_crse  sum_term_crse_crn_hours  \\\n14               Duke,Debra       6.000000                   2228.0   \n31            Sparks,Claire       3.028571                   1573.0   \n8       Chaitankar,Vijender       1.500000                   1251.0   \n3          Budwell,Caroline       2.358824                   1111.0   \n30             Sonmez,Ahmet       2.000000                   1104.0   \n18            Gusukuma,Luke       3.985714                   1019.0   \n11             Dahlberg,Bob       3.108824                    864.0   \n22             Leonard,John       2.608824                    728.0   \n15            Ghosh,Preetam       2.299300                    689.0   \n10          Cranston,Daniel       2.208030                    670.0   \n17              Grove,Ralph       1.285714                    616.0   \n12        Damevski,Kostadin       3.763585                    610.5   \n5             Bulut,Eyuphan       2.776190                    599.5   \n26             Nadeem,Tamer       1.624697                    475.0   \n32          Spinola,Rodrigo       1.144538                    300.0   \n0               Ahmed,Irfan       2.271522                    259.0   \n33  Thomson-McInnes,Bridget       4.660411                    233.0   \n7        Cano Rojas,Alberto       2.227871                    221.0   \n1              Arodz,Tomasz       2.442157                    207.0   \n20            Kurgan,Lukasz       1.585714                    203.0   \n23            Luo,Changqing       2.299300                    183.0   \n24              Manic,Milos       2.212698                    172.0   \n28            Sands,Allison       0.250000                    156.0   \n34               Traub,Adam       0.250000                    156.0   \n27            Nishi,Manziba       1.000000                    126.0   \n6             Byram,Abigail       1.500000                    121.5   \n13               Dinh,Thang       2.136601                    110.0   \n4              Buffkin,Seth       1.500000                    106.5   \n36           Zhou,Hongsheng       2.136601                     89.0   \n21                Lee,Aaron       1.000000                     66.0   \n9            Cios,Krzysztof       0.669935                     55.0   \n2             Bennett,Jason       0.500000                     51.0   \n25            Mizelle,Erika       0.500000                     39.0   \n19         Krawczyk,Bartosz       1.058824                     27.0   \n16            Gill,Satinder       0.050000                     24.0   \n29           Shepherd,David       0.027778                     18.0   \n35                  Ye,Cang       0.027778                      9.0   \n\n    sum_term_crse_wrkld_sample_lec  sum_term_crse_wrkld_sample_non_lec  \\\n14                            12.0                            1.333333   \n31                             7.5                            0.666667   \n8                              3.0                            0.000000   \n3                              6.0                            1.333333   \n30                             4.5                            1.333333   \n18                             6.5                            1.666667   \n11                             5.5                            3.666667   \n22                             3.0                            3.000000   \n15                             3.0                            1.666667   \n10                             3.0                            1.000000   \n17                             2.5                            0.333333   \n12                             2.5                            1.500000   \n5                              2.5                            1.166667   \n26                             2.5                            2.666667   \n32                             1.5                            1.666667   \n0                              2.0                            0.666667   \n33                             2.0                            2.333333   \n7                              2.0                            1.000000   \n1                              2.0                            1.000000   \n20                             2.0                            0.666667   \n23                             2.0                            1.000000   \n24                             2.0                            0.666667   \n28                             1.0                            0.333333   \n34                             1.0                            0.333333   \n27                             1.0                            0.000000   \n6                              1.5                            0.000000   \n13                             2.0                            1.333333   \n4                              1.5                            0.000000   \n36                             2.0                            0.666667   \n21                             1.0                            0.000000   \n9                              1.0                            0.666667   \n2                              0.5                            0.000000   \n25                             0.5                            0.000000   \n19                             1.0                            0.333333   \n16                             0.0                            1.000000   \n29                             0.0                            0.000000   \n35                             0.0                            0.000000   \n\n    sum_term_crse_crn_hours_lec  sum_term_crse_crn_hours_non_lec  \n14                       1696.0                            532.0  \n31                       1265.0                            308.0  \n8                        1251.0                              0.0  \n3                        1007.0                            104.0  \n30                        836.0                            268.0  \n18                        721.0                            298.0  \n11                        786.0                             78.0  \n22                        660.0                             68.0  \n15                        591.0                             98.0  \n10                        633.0                             37.0  \n17                        524.0                             92.0  \n12                        555.0                             55.5  \n5                         510.0                             89.5  \n26                        390.0                             85.0  \n32                        261.0                             39.0  \n0                         165.0                             94.0  \n33                        150.0                             83.0  \n7                         189.0                             32.0  \n1                         189.0                             18.0  \n20                        186.0                             17.0  \n23                        117.0                             66.0  \n24                        129.0                             43.0  \n28                         78.0                             78.0  \n34                         78.0                             78.0  \n27                        126.0                              0.0  \n6                         121.5                              0.0  \n13                         78.0                             32.0  \n4                         106.5                              0.0  \n36                         66.0                             23.0  \n21                         66.0                              0.0  \n9                          12.0                             43.0  \n2                          51.0                              0.0  \n25                         39.0                              0.0  \n19                         21.0                              6.0  \n16                          0.0                             24.0  \n29                          0.0                             18.0  \n35                          0.0                              9.0"
  },
  {
    "objectID": "35_explore2.html#show-summary-table",
    "href": "35_explore2.html#show-summary-table",
    "title": "Exploring instructor measures",
    "section": "Show summary table",
    "text": "Show summary table\n\n# Print table\nMarkdown(tabulate(\n  summary_df, \n  headers=['Instructor','Crses','Hours','Wrkld LEC','Wrkld NON','Hours LEC','Hours NON'],\n  numalign=\"right\",stralign=\"left\",\n  showindex=False,\n  floatfmt=\".1f\"  # Format numbers without decimals\n))\n\n\n\n\nInstructor\nCrses\nHours\nWrkld LEC\nWrkld NON\nHours LEC\nHours NON\n\n\n\n\nDuke,Debra\n6.0\n2228.0\n12.0\n1.3\n1696.0\n532.0\n\n\nSparks,Claire\n3.0\n1573.0\n7.5\n0.7\n1265.0\n308.0\n\n\nChaitankar,Vijender\n1.5\n1251.0\n3.0\n0.0\n1251.0\n0.0\n\n\nBudwell,Caroline\n2.4\n1111.0\n6.0\n1.3\n1007.0\n104.0\n\n\nSonmez,Ahmet\n2.0\n1104.0\n4.5\n1.3\n836.0\n268.0\n\n\nGusukuma,Luke\n4.0\n1019.0\n6.5\n1.7\n721.0\n298.0\n\n\nDahlberg,Bob\n3.1\n864.0\n5.5\n3.7\n786.0\n78.0\n\n\nLeonard,John\n2.6\n728.0\n3.0\n3.0\n660.0\n68.0\n\n\nGhosh,Preetam\n2.3\n689.0\n3.0\n1.7\n591.0\n98.0\n\n\nCranston,Daniel\n2.2\n670.0\n3.0\n1.0\n633.0\n37.0\n\n\nGrove,Ralph\n1.3\n616.0\n2.5\n0.3\n524.0\n92.0\n\n\nDamevski,Kostadin\n3.8\n610.5\n2.5\n1.5\n555.0\n55.5\n\n\nBulut,Eyuphan\n2.8\n599.5\n2.5\n1.2\n510.0\n89.5\n\n\nNadeem,Tamer\n1.6\n475.0\n2.5\n2.7\n390.0\n85.0\n\n\nSpinola,Rodrigo\n1.1\n300.0\n1.5\n1.7\n261.0\n39.0\n\n\nAhmed,Irfan\n2.3\n259.0\n2.0\n0.7\n165.0\n94.0\n\n\nThomson-McInnes,Bridget\n4.7\n233.0\n2.0\n2.3\n150.0\n83.0\n\n\nCano Rojas,Alberto\n2.2\n221.0\n2.0\n1.0\n189.0\n32.0\n\n\nArodz,Tomasz\n2.4\n207.0\n2.0\n1.0\n189.0\n18.0\n\n\nKurgan,Lukasz\n1.6\n203.0\n2.0\n0.7\n186.0\n17.0\n\n\nLuo,Changqing\n2.3\n183.0\n2.0\n1.0\n117.0\n66.0\n\n\nManic,Milos\n2.2\n172.0\n2.0\n0.7\n129.0\n43.0\n\n\nSands,Allison\n0.2\n156.0\n1.0\n0.3\n78.0\n78.0\n\n\nTraub,Adam\n0.2\n156.0\n1.0\n0.3\n78.0\n78.0\n\n\nNishi,Manziba\n1.0\n126.0\n1.0\n0.0\n126.0\n0.0\n\n\nByram,Abigail\n1.5\n121.5\n1.5\n0.0\n121.5\n0.0\n\n\nDinh,Thang\n2.1\n110.0\n2.0\n1.3\n78.0\n32.0\n\n\nBuffkin,Seth\n1.5\n106.5\n1.5\n0.0\n106.5\n0.0\n\n\nZhou,Hongsheng\n2.1\n89.0\n2.0\n0.7\n66.0\n23.0\n\n\nLee,Aaron\n1.0\n66.0\n1.0\n0.0\n66.0\n0.0\n\n\nCios,Krzysztof\n0.7\n55.0\n1.0\n0.7\n12.0\n43.0\n\n\nBennett,Jason\n0.5\n51.0\n0.5\n0.0\n51.0\n0.0\n\n\nMizelle,Erika\n0.5\n39.0\n0.5\n0.0\n39.0\n0.0\n\n\nKrawczyk,Bartosz\n1.1\n27.0\n1.0\n0.3\n21.0\n6.0\n\n\nGill,Satinder\n0.1\n24.0\n0.0\n1.0\n0.0\n24.0\n\n\nShepherd,David\n0.0\n18.0\n0.0\n0.0\n0.0\n18.0\n\n\nYe,Cang\n0.0\n9.0\n0.0\n0.0\n0.0\n9.0"
  },
  {
    "objectID": "35_explore2.html#plot-total-hours-without-colors",
    "href": "35_explore2.html#plot-total-hours-without-colors",
    "title": "Exploring instructor measures",
    "section": "Plot total hours without colors",
    "text": "Plot total hours without colors"
  },
  {
    "objectID": "35_explore2.html#hours-lec-and-non-lec-by-instructor",
    "href": "35_explore2.html#hours-lec-and-non-lec-by-instructor",
    "title": "Exploring instructor measures",
    "section": "Hours (lec and non-lec) by instructor",
    "text": "Hours (lec and non-lec) by instructor\n\nfig, ax = plt.subplots(figsize=(10, 6))\n\nsummary_df = summary_df.sort_values(by='sum_term_crse_crn_hours_lec', ascending=False)\n\ninstructors = summary_df['instructor'].str.split(\",\").str[0]\nlec_hours = summary_df['sum_term_crse_crn_hours_lec']\nnon_lec_hours = summary_df['sum_term_crse_crn_hours_non_lec']\n\n#bottom = np.zeros(len(instructors))\n\np1 = ax.barh(instructors, lec_hours, label='LEC', color='blue')\np2 = ax.barh(instructors, non_lec_hours, left=lec_hours, label='Non-LEC', color='orange')\n\nax.set_xlabel('Total Hours')\nax.set_ylabel('Instructor')\nax.set_title('Instructor Hours by LEC and Non-LEC')\nax.legend()\n\nplt.tick_params(axis='y', labelsize=6)  # Adjust the labelsize as needed\n\nplt.gca().invert_yaxis()\nplt.show()"
  },
  {
    "objectID": "35_explore2.html#workload-by-instructor-and-non-instructor",
    "href": "35_explore2.html#workload-by-instructor-and-non-instructor",
    "title": "Exploring instructor measures",
    "section": "Workload by instructor and non-instructor",
    "text": "Workload by instructor and non-instructor\n\nfig, ax = plt.subplots(figsize=(10, 6))\n\nsummary_df = summary_df.sort_values(by='sum_term_crse_wrkld_sample_lec', ascending=False)\n\ninstructors = summary_df['instructor'].str.split(\",\").str[0]\nlec = summary_df['sum_term_crse_wrkld_sample_lec']\nnon_lec = summary_df['sum_term_crse_wrkld_sample_non_lec']\n\n#bottom = np.zeros(len(instructors))\n\np1 = ax.barh(instructors, lec, label='LEC', color='blue')\np2 = ax.barh(instructors, non_lec, left=lec, label='Non-LEC', color='orange')\n\nax.set_xlabel('Total Hours')\nax.set_ylabel('Instructor')\nax.set_title('Instructor Workload by LEC and Non-LEC')\nax.legend()\n\nplt.tick_params(axis='y', labelsize=6)  # Adjust the labelsize as needed\n\nplt.gca().invert_yaxis()\nplt.show()"
  },
  {
    "objectID": "35_explore2.html#practice-with-multiple-bars",
    "href": "35_explore2.html#practice-with-multiple-bars",
    "title": "Exploring instructor measures",
    "section": "Practice with multiple bars",
    "text": "Practice with multiple bars\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\n\ninstructors = ['Instructor ' + chr(65 + i) for i in range(25)]\nvalues1 = [random.uniform(0., 7.) for _ in range(25)]\nvalues2 = [random.uniform(0., 7,) for _ in range(25)]\n\ndata = {\n    'Instructor': instructors,\n    'Value1': values1,\n    'Value2': values2,\n}\n\n# Create a DataFrame\ndf = pd.DataFrame(data)\ndf = df.sort_values(by='Value2', ascending=True)\n\n# Set the figure size\nplt.figure(figsize=(8, 4))\n\n# Create the left subplot (left bar)\nax1 = plt.subplot(121)\nax1.barh(df['Instructor'], -1.0 * df['Value1'], color='green', label='Left Bar')\nax1.set_xlim(-7, 0)  # Set x-axis limits\nax1.set_xlabel('Values')\nax1.set_title('Left Bar')\nax1.set_yticklabels([\"\"] * len(df['Instructor']))\nax1.yaxis.tick_right()  # Move y-axis ticks to the right\n#ax1.set_yticklabels([])  # Remove y-axis labels\n\n# Remove border from the left subplot\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\n\n# Create the right subplot (right bar)\nax2 = plt.subplot(122)\nax2.barh(df['Instructor'], df['Value2'], color='blue', label='Right Bar')\nax2.set_xlim(0, 7)  # Set x-axis limits\nax2.set_xlabel('Values')\nax2.set_title('Right Bar')\n\n# Remove border from the right subplot\nax2.spines['top'].set_visible(False)\nax2.spines['left'].set_visible(False)\n#ax2.yaxis.tick_right()  # Move y-axis ticks to the right\n\n# Adjust spacing between subplots\nplt.tight_layout()\nplt.tick_params(axis='y', labelsize=6)  # Adjust the labelsize as needed\n\n# Show the plot\nplt.show()\n\nC:\\Users\\jdleonard\\AppData\\Local\\Temp\\ipykernel_45860\\2059536265.py:28: UserWarning:\n\nset_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site was creating in quarto."
  },
  {
    "objectID": "instructor_workload.html",
    "href": "instructor_workload.html",
    "title": "Instructor Workload",
    "section": "",
    "text": "Sort by:   Total Hours Lecture Hours Total Workload Lecture Workload Alphabet \n\n\n\n▲\n\n\n▼\n\n\n\n// Importing D3.js\nd3 = require('d3@6')\n\n\n\n\n\n\n\n// Attach the CSV file\nfileAttachment = FileAttachment(\"selected_data.csv\")\n\n\n\n\n\n\n\n// Load the CSV data\ndata = await fileAttachment.csv()\n\n\n\n\n\n\n\n// Filter and transform data\ntransformedData = data.map(d =&gt; ({\n  instructor: d.instructor,\n  total_hours: +d.sum_term + +d.sum_term_crse + +d.sum_term_crse_crn + +d.sum_term_crse_crn_mtg_students + +d.sum_term_crse_crn_hours,\n  lec_hours: d.wrkld_sample_type === 'LEC' ? +d.sum_term_crse_crn_hours : 0,\n  total_workload: +d.sum_term_crse_wrkld_sample,\n  lec_workload: d.wrkld_sample_type === 'LEC' ? +d.sum_term_crse_wrkld_sample_lec : 0,\n  dept: d.ins_dept,\n  role: d.ins_role,\n  course: d.COURSE\n}));\n\n\n\n\n\n\n\n// aggregate data\naggregatedData = d3.rollups(transformedData, v =&gt; ({\n  total_hours: d3.sum(v, d =&gt; d.total_hours),\n  lec_hours: d3.sum(v, d =&gt; d.lec_hours),\n  total_workload: d3.sum(v, d =&gt; d.total_workload),\n  courses: Array.from(new Set(v.map(d =&gt; d.course))),\n  lec_workload: d3.sum(v, d =&gt; d.lec_workload),\n  ins_dept: v[0].dept,\n  ins_role: v[0].role\n}), d =&gt; d.instructor).map(([instructor, values]) =&gt; ({ instructor, ...values}));\n\n\n\n\n\n\n\nmargin = ({top: 20, right: 20, bottom: 20, left: 40 })\n\n\n\n\n\n\n\nheight = 1700 - margin.top - margin.bottom\n\n\n\n\n\n\n\nwidth = 850 + margin.left - margin.right\n\n\n\n\n\n\n\n{\n  const minHeight = 700;\n  const minWidth = 600;\n\n  const svgWidth = width + margin.left + margin.right;\n  const svgHeight = height + margin.top + margin.bottom;\n\n  let dynamicHeight = Math.max((aggregatedData.length || 0) * 10 + margin.top + margin.bottom, minHeight);\n  let dynamicWidth = Math.max(width, minWidth);\n\n  margin.bottom = Math.max(margin.bottom, 50); // space for x-axis tick marks\n  margin.right = Math.max(margin.right, 150);\n\n  const middleGap = 220;\n  const chartWidth = width/2  - middleGap/2;\n\n  // set up mirrored chart \n  const xScaleLeft = d3.scaleLinear()\n    .domain([0, d3.max(aggregatedData, d =&gt; Math.max(d.total_hours, d.lec_hours))])\n    .range([chartWidth, 0]); // ranging from middle to left \n  \n  const xScaleRight = d3.scaleLinear()\n    .domain([0, d3.max(aggregatedData, d =&gt; Math.max(d.total_workload, d.lec_workload))])\n    .range([width/2 + middleGap/2, width]); // ranging from middle to right\n\n  const yScale = d3.scaleBand()\n    .domain(aggregatedData.map(d =&gt; d.instructor))\n    .range([0, height])\n    .paddingInner(0.1);\n\n  // create svg container\n  const svg = d3.create(\"svg\")\n    .attr('width', svgWidth)\n    .attr('height', svgHeight)\n    .attr(\"viewBox\", `0 0 ${width + margin.left + margin.right} ${dynamicHeight}`)\n    //.style(\"border\", \"1px solid black\");\n\n  const g = svg.append(\"g\").attr(\"transform\", `translate(${margin.left}, ${margin.top})`)\n\n  const chartGroup = svg.append(\"g\").attr(\"transform\", `translate(${margin.left},${margin.top})`);\n\n\n   // Define legend data\n  const legendMarginTop = -30;\n  const legendXStart = margin.left;\n  const legendSpacing = 200;\n  const legendYPosition = legendMarginTop;\n  \n  const legendData = [\n    { color: \"skyblue\", label: \"Total Hours\" },\n    { color: \"blue\", label: \"Lecture Hours\" },\n    { color: \"lightgreen\", label: \"Total Workload\" },\n    { color: \"green\", label: \"Lecture Workload\" }\n  ];\n\n  // Position the legend at the top within the newly adjusted margin space\n  const legend = chartGroup.selectAll(\".legend\")\n    .data(legendData)\n    .enter().append(\"g\")\n      .attr(\"class\", \"legend\")\n      .attr(\"transform\", (d, i) =&gt; `translate(${legendXStart + i * legendSpacing}, ${-margin.top + legendMarginTop})`);\n  \n  legend.append(\"rect\")\n      .attr(\"x\", 30)\n      .attr(\"y\", 0)\n      .attr(\"width\", 18)\n      .attr(\"height\", 18)\n      .style(\"fill\", d =&gt; d.color);\n  \n  legend.append(\"text\")\n      .attr(\"x\", 24)\n      .attr(\"y\", 9)\n      .attr(\"dy\", \".35em\")\n      .style(\"text-anchor\", \"end\")\n      .text(d =&gt; d.label);\n\n  // check boxes\n  const departments = [\n    'CMSC', 'EGRB', 'EGRC', 'EGRE', 'EGRM', 'ENGR', 'INNO', 'EBRC', 'COAR'\n  ];\n\n  const roles = [\n    'TTT', 'Adjunct', 'Term'\n  ]\n  \n  const checkboxSize = 15; // Size of the checkbox\n  const spacing = 20; // Spacing between checkboxes\n  \n  // Initial filter state\n  let selectedDepartments = new Set();\n  let selectedRoles = new Set();\n\n  const rightMargin = 0;\n  const checkBoxStartX = width - rightMargin;\n\n  // Add headings for Departments and Roles\n  svg.append('text')\n      .attr('x', checkBoxStartX)\n      .attr('y', 20)\n      .text('Departments:')\n      .style('font-weight', 'bold');\n  \n  svg.append('text')\n      .attr('x', checkBoxStartX)\n      .attr('y', 40 + (departments.length + 1) * spacing)\n      .text('Roles:')\n      .style('font-weight', 'bold');\n  \n  // Draw checkboxes for departments\n  departments.forEach((dept, index) =&gt; {\n      const group = svg.append('g')\n          .attr('transform', `translate(${checkBoxStartX}, ${40 + index * spacing})`)\n          .attr('class', 'dept-filter')\n          .style('cursor', 'pointer')\n          .on('click', function() {\n              if (selectedDepartments.has(dept)) {\n                  selectedDepartments.delete(dept);\n                  d3.select(this).select('rect').attr('fill', 'none');\n              } else {\n                  selectedDepartments.add(dept);\n                  d3.select(this).select('rect').attr('fill', 'black');\n              }\n              //applyFilters();\n              applyCurrentState();\n          });\n  \n      group.append('rect')\n          .attr('width', checkboxSize)\n          .attr('height', checkboxSize)\n          .attr('fill', selectedDepartments.has(dept) ? 'black' : 'none')\n          .attr('stroke', 'black');\n  \n      group.append('text')\n          .attr('x', checkboxSize + 5)\n          .attr('y', checkboxSize / 2)\n          .attr('alignment-baseline', 'middle')\n          .text(dept);\n  });\n  \n  // Draw checkboxes for roles\n  roles.forEach((role, index) =&gt; {\n      const group = svg.append('g')\n          .attr('transform', `translate(${checkBoxStartX}, ${40 + (departments.length + 1) * spacing + (index + 1) * spacing})`)\n          .attr('class', 'role-filter')\n          .style('cursor', 'pointer')\n          .on('click', function() {\n              if (selectedRoles.has(role)) {\n                  selectedRoles.delete(role);\n                  d3.select(this).select('rect').attr('fill', 'none');\n              } else {\n                  selectedRoles.add(role);\n                  d3.select(this).select('rect').attr('fill', 'black');\n              }\n              //applyFilters();\n              applyCurrentState();\n          });\n  \n      group.append('rect')\n          .attr('width', checkboxSize)\n          .attr('height', checkboxSize)\n          .attr('fill', selectedRoles.has(role) ? 'black' : 'none')\n          .attr('stroke', 'black');\n  \n      group.append('text')\n          .attr('x', checkboxSize + 5)\n          .attr('y', checkboxSize / 2)\n          .attr('alignment-baseline', 'middle')\n          .text(role);\n  });\n\n  // tick line\n  const axisOffset = 50; // amount to move the axis down \n  const axisOffset2 = 70; //extend length of tick line \n  \n  const xAxisLeft = d3.axisBottom(xScaleLeft)\n    .ticks(5)\n    .tickSizeInner(-(height - margin.top - margin.bottom + axisOffset2))\n    .tickSizeOuter(0);\n\n  const xAxisRight = d3.axisBottom(xScaleRight)\n    .ticks(5)\n    .tickSizeInner(-(height - margin.top - margin.bottom + axisOffset2))\n    .tickSizeOuter(0);\n\n  svg.append(\"g\")\n    .attr(\"class\", \"x-axis-left\")\n    .attr(\"transform\", `translate(0, ${height - margin.bottom + axisOffset})`)\n    .call(xAxisLeft)\n    .selectAll(\".tick line\") \n    .attr(\"stroke\", \"#ccc\");\n  \n  svg.append(\"g\")\n    .attr(\"class\", \"x-axis-right\")\n    .attr(\"transform\", `translate(0, ${height - margin.bottom + axisOffset})`)\n    .call(xAxisRight)\n    .selectAll(\".tick line\") \n    .attr(\"stroke\", \"#ccc\");\n\n  // Create a tooltip div that is hidden by default\n  var tooltip = d3.select(\"body\").append(\"div\")\n    .attr(\"class\", \"tooltip\")\n    .style(\"opacity\", 0)\n    .style(\"position\", \"absolute\")\n    .style(\"text-align\", \"center\")\n    .style(\"width\", \"150px\")\n    .style(\"height\", \"auto\")\n    .style(\"padding\", \"2px\")\n    .style(\"font\", \"12px sans-serif\")\n    .style(\"color\", \"white\")\n    .style(\"background\", \"black\")\n    .style(\"border\", \"0px\")\n    .style(\"border-radius\", \"8px\")\n    .style(\"pointer-events\", \"none\");\n\n  // labels\n  const instructorXPosition = width/2 + 15;\n  svg.selectAll(\".label-instructor\") // append instructor - middleGap\n   .data(aggregatedData)\n   .enter().append(\"text\")\n     .attr(\"class\", \"label-instructor\")\n     .attr(\"x\", instructorXPosition)\n     .attr(\"y\", d =&gt; yScale(d.instructor) + yScale.bandwidth() / 2)\n     .attr(\"dy\", \".35em\")\n     .attr(\"text-anchor\", \"end\")\n     .text(d =&gt; d.instructor)\n     .style(\"font-size\", \"10px\");\n\n  const departmentXPosition = width/2 + 25;\n  svg.selectAll(\".label-department\") // append departments - middleGap\n     .data(aggregatedData)\n     .enter().append(\"text\")\n     .attr(\"class\", \"label-department\")\n     .attr(\"x\", departmentXPosition)\n     .attr(\"y\", d =&gt; yScale(d.instructor) + yScale.bandwidth() / 2)\n     .attr(\"dy\", \".35em\")\n     .attr(\"text-anchor\", \"start\")\n     .text(d =&gt; d.ins_dept)\n     .style(\"font-size\", \"10px\");\n\n  const roleXPosition = width/2 + 80;\n  // Append roles\n  svg.selectAll(\".label-role\")\n     .data(aggregatedData)\n     .enter().append(\"text\")\n     .attr(\"class\", \"label-role\")\n     .attr(\"x\", roleXPosition)\n     .attr(\"y\", d =&gt; yScale(d.instructor) + yScale.bandwidth() / 2)\n     .attr(\"dy\", \".35em\")\n     .attr(\"text-anchor\", \"middle\")\n     .text(d =&gt; `(${d.ins_role})`)\n     .style(\"font-size\", \"10px\");\n\n  // draw bars - middleGap\n  svg.selectAll(\".bar-total-hours\")\n    .data(aggregatedData)\n    .enter().append(\"rect\")\n      .attr(\"class\", \"bar-total-hours\")\n      .attr(\"x\", d =&gt; xScaleLeft(d.total_hours))\n      .attr(\"y\", d =&gt; yScale(d.instructor))\n      .attr(\"width\", d =&gt; chartWidth - xScaleLeft(d.total_hours))\n      .attr(\"height\", yScale.bandwidth())\n      .attr(\"fill\", \"skyblue\");\n\n  svg.selectAll(\".bar-lec-hours\")\n    .data(aggregatedData)\n    .enter().append(\"rect\")\n      .attr(\"class\", \"bar-lec-hours\")\n      .attr(\"x\", d =&gt; xScaleLeft(d.lec_hours))\n      .attr(\"y\", d =&gt; yScale(d.instructor))\n      .attr(\"width\", d =&gt; chartWidth - xScaleLeft(d.lec_hours))\n      .attr(\"height\", yScale.bandwidth())\n      .attr(\"fill\", \"blue\");\n\n  svg.selectAll(\".bar-total-workload\")\n    .data(aggregatedData)\n    .enter().append(\"rect\")\n      .attr(\"class\", \"bar-total-workload\")\n      .attr(\"x\", width/2 + middleGap/2)\n      .attr(\"y\", d =&gt; yScale(d.instructor))\n      .attr(\"width\", d =&gt; xScaleRight(d.total_workload) - (width/2 + middleGap/2))\n      .attr(\"height\", yScale.bandwidth())\n      .attr(\"fill\", \"lightgreen\");\n\n  svg.selectAll(\".bar-lec-workload\")\n    .data(aggregatedData)\n    .enter().append(\"rect\")\n      .attr(\"class\", \"bar-lec-workload\")\n      .attr(\"x\", width/2 + middleGap/2)\n      .attr(\"y\", d =&gt; yScale(d.instructor))\n      .attr(\"width\", d =&gt; xScaleRight(d.lec_workload) - (width/2 + middleGap/2))\n      .attr(\"height\", yScale.bandwidth())\n      .attr(\"fill\", \"green\");\n\n  let currentState = {\n    sortCriterion: null,\n    sortOrderAscending: true,\n    selectedDepartments: new Set(),\n    selectedRoles: new Set()\n  }\n\n   // Sort helper functions\n  function sortAscending(criterion) {\n    return (a, b) =&gt; {\n      if (typeof a[criterion] === 'string') {\n        return a[criterion].localeCompare(b[criterion]);\n      }\n      return a[criterion] - b[criterion];\n    };\n  }\n\n  function sortDescending(criterion) {\n    return (a, b) =&gt; {\n      if (typeof a [criterion] === 'string') {\n        return b[criterion].localeCompare(a[criterion]);\n      }\n      return b[criterion] - a[criterion];\n    };\n  }\n\n  function sortData(criterion, ascending) {\n    currentState.sortCriterion = criterion;\n    currentState.sortOrderAscending = ascending;\n    applyCurrentState();\n  }\n  \n    // Function to update filtering state and apply changes\n  function filterData() {\n    currentState.selectedDepartments = new Set(\n      d3.selectAll(\".dept-filter:checked\").nodes().map(d =&gt; d.value)\n    );\n\n    currentState.selectedRoles = new Set(\n      d3.selectAll(\".role-filter:checked\").nodes().map(d =&gt; d.value)\n    ); \n    \n    applyCurrentState();\n  }\n\n  // Function to update bars\n  function updateBars(selector, data, xScale, fillColor, transition, isRightSide) {\n      let bars = svg.selectAll(selector)\n          .data(data, d =&gt; d.instructor);\n  \n      // Enter and Update selections\n      bars.enter().append(\"rect\")\n          .attr(\"class\", selector.replace('.', ''))\n          .attr(\"fill\", fillColor)\n          .merge(bars) // Merging enter and update selections\n          .transition(transition)\n          .attr(\"x\", d =&gt; isRightSide ? width / 2 : xScale(d.total_hours))\n          .attr(\"y\", d =&gt; yScale(d.instructor))\n          .attr(\"width\", d =&gt; isRightSide ? xScale(d.total_workload) - (width / 2) : (width / 2 - middleGap) - xScale(d.total_hours))\n          .attr(\"height\", yScale.bandwidth());\n  \n      // Exit selection\n      bars.exit().remove();\n  }\n  \n  // Function to update labels\n  function updateLabels(selector, data, xPos, textAccessor, transition) {\n      let labels = svg.selectAll(selector)\n                      .data(data, d =&gt; d.instructor);\n  \n      labels.enter().append(\"text\")\n          .attr(\"class\", selector.substring(1)) \n          .merge(labels)\n          .transition(transition)\n          .attr(\"x\", xPos)\n          .attr(\"y\", d =&gt; yScale(d.instructor) + yScale.bandwidth() / 2)\n          .attr(\"dy\", \".35em\")\n          .text(textAccessor);\n     labels.exit().remove();\n  }\n  \n   function updateChart(displayData) {\n      // Update yScale's range and domain\n      yScale.domain(displayData.map(d =&gt; d.instructor))\n            .padding(0.1);\n  \n      // Transition for bars and labels\n      const t = svg.transition().duration(500);\n  \n      // Update chart elements in updateChart function\n      updateBars(\".bar-total-hours\", displayData, xScaleLeft, \"skyblue\", t, false);  // Left side bar\n      updateBars(\".bar-lec-hours\", displayData, xScaleLeft, \"blue\", t, false);      // Left side bar\n      updateBars(\".bar-total-workload\", displayData, xScaleRight, \"lightgreen\", t, true); // Right side bar\n      updateBars(\".bar-lec-workload\", displayData, xScaleRight, \"green\", t, true);   // Right side bar\n       \n      // Update labels\n      updateLabels(\".label-instructor\", displayData, instructorXPosition, d =&gt; d.instructor, t);\n      updateLabels(\".label-department\", displayData, departmentXPosition, d =&gt; d.ins_dept, t);\n      updateLabels(\".label-role\", displayData, roleXPosition, d =&gt; `(${d.ins_role})`, t);\n  \n  \n      // Select and bind data for total hours bars\n      let barsTotalHours = svg.selectAll(\".bar-total-hours\")\n                              .data(displayData, d =&gt; d.instructor);\n      \n      // Enter + Update Selection for total hours bars\n      barsTotalHours.enter().append(\"rect\")\n          .attr(\"class\", \"bar-total-hours\")\n          // Initial attributes for new elements\n          .attr(\"fill\", \"skyblue\")\n          .merge(barsTotalHours) // Merging enter and update selections\n          // Add mouse event\n          .on(\"mouseover\", function(event, d) {\n              let format = d3.format(\".2f\");\n              tooltip.transition()\n                  .duration(200)\n                  .style(\"opacity\", .9);\n              tooltip.html(`\n                  &lt;div class=\"tooltip-content\"&gt;\n                      &lt;strong&gt;${d.instructor}&lt;/strong&gt;&lt;br&gt;\n                      &lt;span class=\"tooltip-text\"&gt;Total Hours: ${format(d.total_hours)}&lt;/span&gt;&lt;br&gt;\n                      &lt;ul&gt;${d.courses.map(course =&gt; `&lt;li&gt;${course}&lt;/li&gt;`).join('')}&lt;/ul&gt;\n                  &lt;/div&gt;\n              `)\n                  .style(\"left\", (event.pageX + 5) + \"px\")\n                  .style(\"top\", (event.pageY - 28) + \"px\");\n          })\n          .on(\"mouseout\", function() {\n              tooltip.transition()\n                  .duration(500)\n                  .style(\"opacity\", 0);\n          })\n          .transition(t)\n          .attr(\"x\", d =&gt; xScaleLeft(d.total_hours))\n          .attr(\"y\", d =&gt; yScale(d.instructor))\n          .attr(\"width\", d =&gt; chartWidth - xScaleLeft(d.total_hours))\n          .attr(\"height\", yScale.bandwidth());\n   \n      barsTotalHours.exit().remove();\n  \n      \n      // Select and bind data for lecture hours bars\n      let barsLectureHours = svg.selectAll(\".bar-lec-hours\")\n                                .data(displayData, d =&gt; d.instructor);\n        \n        // Enter + Update Selection for lecture hours bars\n        barsLectureHours.enter().append(\"rect\")\n            .attr(\"class\", \"bar-lec-hours\")\n            .attr(\"fill\", \"blue\")\n            .merge(barsLectureHours)\n            // add mouse event\n            .on(\"mouseover\", function(event, d) {\n                let format = d3.format(\".2f\");\n                tooltip.transition()\n                    .duration(200)\n                    .style(\"opacity\", .9);\n                tooltip.html(`\n                  &lt;div class=\"tooltip-content\"&gt;\n                      &lt;strong&gt;${d.instructor}&lt;/strong&gt;&lt;br&gt;\n                      &lt;span class=\"tooltip-text\"&gt;Lecture Hours: ${format(d.lec_hours)}&lt;/span&gt;&lt;br&gt;\n                      &lt;ul&gt;${d.courses.map(course =&gt; `&lt;li&gt;${course}&lt;/li&gt;`).join('')}&lt;/ul&gt;\n                  &lt;/div&gt;\n                `)\n                    .style(\"left\", (event.pageX + 5) + \"px\")\n                    .style(\"top\", (event.pageY - 28) + \"px\");\n            })\n            .on(\"mouseout\", function() {\n                tooltip.transition()\n                    .duration(500)\n                    .style(\"opacity\", 0);\n            })\n            .transition(t)\n            .attr(\"x\", d =&gt; xScaleLeft(d.lec_hours))\n            .attr(\"y\", d =&gt; yScale(d.instructor))\n            .attr(\"width\", d =&gt; chartWidth - xScaleLeft(d.lec_hours))\n            .attr(\"height\", yScale.bandwidth());\n            \n        barsLectureHours.exit().remove();\n  \n      \n      let barsTotalWorkload = svg.selectAll(\".bar-total-workload\")\n                       .data(displayData, d =&gt; d.instructor);\n\n        barsTotalWorkload.enter().append(\"rect\")\n            .merge(barsTotalWorkload)\n            .attr(\"class\", \"bar-total-workload\")\n            .attr(\"x\", width/2 + middleGap/2)\n            .attr(\"y\", d =&gt; yScale(d.instructor))\n            .attr(\"width\", d =&gt; xScaleRight(d.total_workload) - (width/2 + middleGap/2))\n            .attr(\"height\", yScale.bandwidth())\n            .attr(\"fill\", \"lightgreen\")\n              // Add mouse event\n            .on(\"mouseover\", function(event, d) {\n                let format = d3.format(\".2f\");\n                tooltip.transition()\n                    .duration(200)\n                    .style(\"opacity\", 0.9);\n                tooltip.html(`\n                  &lt;div class=\"tooltip-content\"&gt;\n                      &lt;strong&gt;${d.instructor}&lt;/strong&gt;&lt;br&gt;\n                      &lt;span class=\"tooltip-text\"&gt;Total Workload: ${format(d.total_workload)}&lt;/span&gt;&lt;br&gt;\n                      &lt;ul&gt;${d.courses.map(course =&gt; `&lt;li&gt;${course}&lt;/li&gt;`).join('')}&lt;/ul&gt;\n                  &lt;/div&gt;\n                `)\n                    .style(\"left\", (event.pageX + 10) + \"px\")\n                    .style(\"top\", (event.pageY - 15) + \"px\");\n            })\n            .on(\"mouseout\", function() {\n                tooltip.transition()\n                    .duration(500)\n                    .style(\"opacity\", 0);\n            });\n              \n        barsTotalWorkload.transition(t)\n            .attr(\"x\", width/2 + middleGap/2)\n            .attr(\"y\", d =&gt; yScale(d.instructor))\n            .attr(\"y\", d =&gt; yScale(d.instructor))\n            .attr(\"width\",  d =&gt; xScaleRight(d.total_workload) - (width/2 + middleGap/2));\n        \n        barsTotalWorkload.exit().remove();\n\n     let barsLectureWorkload = svg.selectAll(\".bar-lec-workload\")\n                               .data(displayData, d =&gt; d.instructor);\n        \n        barsLectureWorkload.enter().append(\"rect\")\n            .attr(\"class\", \"bar-lec-workload\")\n            .merge(barsLectureWorkload)\n            .attr(\"x\", width/2 + middleGap/2)\n            .attr(\"y\", d =&gt; yScale(d.instructor))\n            .attr(\"width\", d =&gt; xScaleRight(d.lec_workload) - (width/2 + middleGap/2))\n            .attr(\"height\", yScale.bandwidth())\n            .attr(\"fill\", \"green\")\n              // Add mouse event\n            .on(\"mouseover\", function(event, d) {\n                let format = d3.format(\".2f\");\n                tooltip.transition()\n                    .duration(200)\n                    .style(\"opacity\", 0.9);\n                tooltip.html(`\n                  &lt;div class=\"tooltip-content\"&gt;\n                      &lt;strong&gt;${d.instructor}&lt;/strong&gt;&lt;br&gt;\n                      &lt;span class=\"tooltip-text\"&gt; Lecture Workload: ${format(d.lec_workload)}&lt;/span&gt;&lt;br&gt;\n                      &lt;ul&gt;${d.courses.map(course =&gt; `&lt;li&gt;${course}&lt;/li&gt;`).join('')}&lt;/ul&gt;\n                  &lt;/div&gt;\n                `)\n                    .style(\"left\", (event.pageX + 10) + \"px\")\n                    .style(\"top\", (event.pageY - 15) + \"px\");\n            })\n            .on(\"mouseout\", function() {\n                tooltip.transition()\n                    .duration(500)\n                    .style(\"opacity\", 0);\n            });\n        \n          barsLectureWorkload.transition(t)\n              .attr(\"x\", width/2 + middleGap/2)\n              .attr(\"y\", d =&gt; yScale(d.instructor))\n              .attr(\"y\", d =&gt; yScale(d.instructor))\n              .attr(\"width\", d =&gt; xScaleRight(d.lec_workload) - (width/2 + middleGap/2));\n          \n          barsLectureWorkload.exit().remove();\n    \n      // Update instructor labels\n     let instructorLabels = svg.selectAll(\".label-instructor\")\n                            .data(displayData, d =&gt; d.instructor);\n  \n        instructorLabels.enter().append(\"text\")\n            .attr(\"class\", \"label-instructor\")\n            .merge(instructorLabels) // merge enter and update selections\n            .transition(t)\n            .attr(\"x\", instructorXPosition)\n            .attr(\"y\", d =&gt; yScale(d.instructor) + yScale.bandwidth() / 2)\n            .attr(\"dy\", \".35em\")\n            .attr(\"text-anchor\", \"end\")\n            .text(d =&gt; d.instructor)\n            .style(\"font-size\", \"10px\");\n        \n        instructorLabels.exit().remove();\n      \n      // Update department labels\n      let departmentLabels = svg.selectAll(\".label-department\")\n                                .data(displayData, d =&gt; d.instructor);\n      \n        departmentLabels.enter().append(\"text\")\n            .attr(\"class\", \"label-department\")\n            .merge(departmentLabels) \n            .transition(t)\n            .attr(\"x\", departmentXPosition)\n            .attr(\"y\", d =&gt; yScale(d.instructor) + yScale.bandwidth() / 2)\n            .attr(\"dy\", \".35em\")\n            .attr(\"text-anchor\", \"start\")\n            .text(d =&gt; d.ins_dept)\n            .style(\"font-size\", \"10px\");\n        \n        departmentLabels.exit().remove();\n      \n          \n      // Update role labels\n      let roleLabels = svg.selectAll(\".label-role\")\n                      .data(displayData, d =&gt; d.instructor);\n  \n        roleLabels.enter().append(\"text\")\n            .attr(\"class\", \"label-role\")\n            .merge(roleLabels) \n            .transition(t)\n            .attr(\"x\", roleXPosition)\n            .attr(\"y\", d =&gt; yScale(d.instructor) + yScale.bandwidth() / 2)\n            .attr(\"dy\", \".35em\")\n            .attr(\"text-anchor\", \"middle\")\n            .text(d =&gt; `(${d.ins_role})`)\n            .style(\"font-size\", \"10px\");\n        \n        roleLabels.exit().remove();\n  \n   }\n  \n    // Attach event listeners to filter checkboxes\n    d3.selectAll(\".dept-filter, .role-filter\").on(\"change\", filterData);\n\n    // Function to apply sorting and filtering\n  function applyCurrentState() {\n    // Apply filter first\n    let filteredData = aggregatedData.filter(d =&gt; \n      (selectedDepartments.size === 0 || selectedDepartments.has(d.ins_dept)) &&\n      (selectedRoles.size === 0 || selectedRoles.has(d.ins_role))\n    );\n  \n    // Then apply sorting\n    if (currentState.sortCriterion) {\n      const sortFunction = currentState.sortOrderAscending\n        ? sortAscending(currentState.sortCriterion)\n        : sortDescending(currentState.sortCriterion);\n      filteredData.sort(sortFunction);\n    }\n  \n    // Update the charts with the filtered and sorted data\n    updateChart(filteredData);\n  }\n  \n  applyCurrentState();\n\n  // Function to attach event listeners to sorting controls\n  function attachSortingEventListeners() {\n    // Listen for changes on the dropdown menu\n    d3.select(\"#sorting-criteria\").on(\"change\", function() {\n      const selectedCriterion = d3.select(this).node().value;\n      // ascending sort as default action\n      sortData(selectedCriterion, true);\n    });\n  \n    // Attach event listeners for sorting\n    d3.select(\"#sort-asc\").on(\"click\", function() {\n      const selectedCriterion = d3.select(\"#sorting-criteria\").property(\"value\");\n      sortData(selectedCriterion, true); \n    });\n    \n    d3.select(\"#sort-desc\").on(\"click\", function() {\n      const selectedCriterion = d3.select(\"#sorting-criteria\").property(\"value\");\n      sortData(selectedCriterion, false); \n    });\n  }\n\n  attachSortingEventListeners();      \n\n  return svg.node();\n}"
  }
]